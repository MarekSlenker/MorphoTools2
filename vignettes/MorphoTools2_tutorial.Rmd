---
title: \vspace{+2.0cm} MorphoTools2 version 1.0.0 tutorial \vspace{+2.0cm}
author: |
  | developed by **Marek Šlenker**\footnotemark[2] \footnotemark[3] \footnotemark[1] \vspace*{0.5pc}
  | with contribution from **Petr Koutecký**\footnotemark[4] &nbsp;and **Karol Marhold**\footnotemark[2] \footnotemark[3] \vspace*{0.7pc}
  | *https://github.com/MarekSlenker/MorphoTools2*
  | \vspace*{0.7pc}
date: "Date: Jun 2021"
output:
  pdf_document: default
vignette: |
  %\VignetteIndexEntry{MorphoTools2_tutorial}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---
&nbsp;  
\renewcommand{\thefootnote}{\fnsymbol{footnote}}	
\footnotetext[2]{Slovak Academy of Sciences, Bratislava, Slovakia}
\footnotetext[3]{Charles University, Prague, Czechia}  
\footnotetext[4]{University of South Bohemia, České Budějovice, Czechia \vspace*{0.4pc}}
\footnotetext[1]{author for correspondence: marek.slenker@savba.sk}


\newpage 

```{r, include = FALSE}
knitr::opts_chunk$set(
  highlight = TRUE,
  dpi = 300,
  collapse = TRUE,
  comment = "#>",
  rownames = FALSE, 
  fig.width   = 6,      
  fig.height  = 5,      
  fig.align   = 'center',
  #fig.path    = 'figs/', 
  strip.white = TRUE    
  #out.width='\\textwidth'
  )
```

```{=latex}
\renewcommand{\baselinestretch}{0.4}
\setcounter{tocdepth}{4}
\tableofcontents
\renewcommand{\baselinestretch}{1.0}\normalsize

```



# 1. Introduction

The package `MorphoTools2` is dedicated to multivariate analyses of morphological data. The needed tools are at the moment scattered over several R packages. This package wraps available statistical and graphical tools and provides a comprehensive framework for control and manipulation of the input data, core statistical analysis and the wide palette of functions designed to visualize results, to make the workflow convenient and fast.

\renewcommand{\thefootnote}{\arabic{footnote}}

# 2. Obtaining and installing MorphoTools2 package

The R console and base system can be downloaded at <http://www.r-project.org/>. Once R is installed, `MorphoTools2` can be installed and loaded by typing the following commands into the R console:


```{r eval=FALSE, include=TRUE}
install.packages(MorphoTools2)
library(MorphoTools2)

```
```{r include=FALSE, eval=TRUE}
library(MorphoTools2)
```

To get the latest version of `MorphoTools2` package, install it using the `devtools::install_github()` function from the `devtools` package.

```{r include=TRUE, eval=FALSE}
install.packages("devtools")
devtools::install_github("MarekSlenker/MorphoTools2")
```

After quiting or restarting R, package need to be loaded again (using the `library` function as shown above).

# 3. Data import, control and manipulation

As with any statistical software, the first task is to import raw data. However, raw data can contain errors (e.g., typos in numbers or decimal points) and missing values which should be corrected or removed. We should also consider removing significantly correlated characters, that could potentially distort the results of some of the multivariate analyses. Moreover, an assessment of the normality of distribution of data is a prerequisite for some statistical tests. If this assumption is not met, the distribution of data can be improved by transformation, or nonparametric methods that do not require normality of distribution of data can be preferred. The following chapters go through these issues and end up with the cleaned data ready for exploring the morphological differentiation among the taxa (or any defined groups).


## 3.1 Data import

Data can be imported from plain text files (tab, comma, or whitespace delimited, see below), or from Excel spreadsheets through the clipboard in Windows. Following structure of input data is required: 

* the first row contains variable names.
* the next rows contain individuals (samples, or any other kind of sampling units), single individual per row.
* the first three columns include unique identifiers for individuals, populations and taxa/groups, respectively. Columns have to be named as “ID”, “Population” and “Taxon”[^1].
* fourth and next columns stores morphological characters[^2].

[^1]: In case the **population level is missing or inapplicable** (e.g. more than one individual only in some populations and/or very low number of individuals per population), copy the values from the"ID" column to "Population" column; this will allow analysing such data by most methods but any analyses considering population level are meaningless.

[^2]: **The morphological characters** can be quantitative, binary (coded as 0/1), or multi-state ordered categorical (semiquantitative, rank-ordered) characters  (e.g., 1 = small, 2 = medium, 3 = large, where change from state 1 to 3 is more costly than change from 1 to 2). On the other hand, nonordered categorical (qualitative, nominal) characters (e.g. describing colour: 1 = red, 2 = green, 3 = blue) are not applicable in most of the analyses (e.g., principal component or discriminant analyses). If there is a reason to include such unordered multistate characters, these characters either have to be coded as binary characters, as follows: redFlowers (0/1), greenFlowers (0/1), blueFlowers (0/1), or, in some cases coefficients for mixed data (e.g., Gower coefficient) should be used.



| ID      	| Population 	| Taxon 	| SN   	| SF   	| ST   	| SFT  	| LL   	| LW  	| LLW  	|
|---------	|------------	|-------	|------	|------	|------	|------	|------	|-----	|------	|
| RTE1    	| RTE        	| hybr  	| 35.2 	| 23.6 	| 58.8 	| 0.4  	| 11.2 	| 3.9 	| 2.87 	|
| RTE2    	| RTE        	| hybr  	| 39   	| 11.8 	| 50.8 	| 0.23 	| 7.2  	| 2.6 	| 2.77 	|
| RUS112  	| RUS        	| hybr  	| 24.8 	| 23.4 	| 48.2 	| 0.49 	| 7.1  	| 2.8 	| 2.54 	|
| RUS113  	| RUS        	| hybr  	| 30   	| 25.5 	| 55.5 	| 0.46 	| 10.2 	| 3.7 	| 2.76 	|
| OLE1272 	| OLE1       	| ps    	| 48.6 	| 6.3  	| 54.9 	| 0.11 	| 8.6  	| 3.8 	| 2.26 	|
| OLE1273 	| OLE1       	| ps    	| 58.1 	| 10   	| 68.1 	| 0.15 	| 11.2 	| 3.7 	| 3.03 	|
| OLE1274 	| OLE1       	| ps    	| 30.7 	| 26.6 	| 57.3 	| 0.46 	| 7.9  	| 3.1 	| 2.55 	|
| STGH309 	| STGH       	| ps    	| 77.1 	| 15.5 	| 92.6 	| 0.17 	| 11.6 	| 3.9 	| 2.97 	|
| STGH310 	| STGH       	| ps    	| 35.6 	| 19.2 	| 54.8 	| 0.35 	| 9.5  	|     	| *NA* 	|


Use underscores (_) instead of spaces, and avoid special characters (e.g. punctuation marks). Missing values have to be represented as empty cells or by the text `NA` (not quoted).

In this tutorial, we will use the centaurea dataset, containing measurements of 25 morphological characters of three diploid species of the *Centaurea phrygia* complex: *C. phrygia* s.str. (abbreviated "ph"), *C. pseudophrygia* ("ps") and *C. stenolepis* ("st") and the putative hybrid of the last two species abbreviated as "hybr" (for details, see Koutecký, 2015). The centaurea dataset is built-in in this package. Execute command `data(centaurea)` to load this data to R workspace.

```{r eval = TRUE, echo = TRUE}
data(centaurea)
```


In general, morphological data can be imported using the `read.morphodata()` function, providing path to data[^3]. Argument `dec` stands for the character used in the file for decimal separator, `sep` is a column delimiter character, usually blank space `""`, comma `","` or tab `"\t"`. The default values are a dot and tab (`"\t"`), respectively, and these may be omitted from the function call. To read data from clipboard (select cells in the Excel spreadsheet, press Ctrl+C ), set `file = "clipboard"`.

[^3]: **Example dataset** in txt and xlsx formats are stored in the "extdata" directory of the MorphoTools2 package installation directory. To find the path to the package location run `system.file("extdata", package = "MorphoTools2")`.

```{r eval = FALSE, echo = TRUE}
centaurea = read.morphodata(file = "<PATH TO centaurea.txt>", dec = ".", sep = "\t")
```

```{r eval = FALSE, echo = TRUE}
centaurea = read.morphodata(file = "clipboard")
```


The dataset now exists as a `morphodata` object in R. The `morphodata` object, as well as other objects used later, is defined as a `list`. In R lists act as containers for data. Elements stored in `morphodata` object can be referenced by the `$` notation. Type `centaurea$` and press the tab key to see contained elements. Command `centaurea$Taxon` print values on R console. Run `?morphodata` to see what a `morphodata` object contains. 

Alternatively, the following commands display basic information about the dataset or show data in the data viewer.

```{r echo = FALSE, eval = TRUE}
summary<-function(object){
  cat("object of class \'morphodata\'\
- contains 33 populations
- contains 4 defined groups (taxa)

Populations: BABL, BABU, BOL, BRT, BUK, CERM, CERV, CZLE, DEB, DOM, DUB, HVLT, KASH,
 KOT, KOZH, KRO, LES, LIP, MIL, NEJ, NSED, OLE1, OLE2, PREL, PRIS, PROS, RTE, RUS,
 SOK, STCV, STGH, VIT, VOL
Groups (taxa): hybr, ph, ps, st\n")
}
```
```{r echo = TRUE, eval=TRUE, collapse=TRUE}
summary(centaurea)
```
```{r echo = FALSE, eval = TRUE}
rm(summary)
```

```{r include=F}
options(max.print = 60)
```
```{r echo = TRUE, eval=TRUE}
samples(centaurea)
```

```{r echo = TRUE, eval=TRUE}
populations(centaurea)
```

```{r echo = TRUE, eval=TRUE}
taxa(centaurea)
```

```{r echo = TRUE, eval=TRUE}
characters(centaurea)
```

```{r echo = TRUE, eval=FALSE}
viewMorphodata(centaurea)
```


## 3.2 Assessing whether the data follow normal distribution

An assessment whether the data follow normal distribution is a prerequisite for many statistical tests, but on the other hand, many analyses are quite robust to moderate deviations from normality. From the here used analyses, normality of distribution is required by Pearson correlation coefficient and Discriminant analysis (both canonical and linear or quadratic classificatory analysis). The normality of distribution of data is not an inevitable assumption of the Hierarchical clustering, Principal component analysis, Principal coordinates analysis, nor Non-metric multidimensional scaling.  
There are two main methods of assessing normality: numerically or graphically. Please note, although all methods available in `MorphoTools2` package are presented here, there is no need to use all of these methods at once. What we need is only a brief summary of whether the data are normally distributed or not.    

### 3.2.1 Shapiro-Wilk normality test  

The normality of distribution of each character on the level of taxon/group can be tested using the Shapiro-Wilk statistic. If the calculated p-value of a certain character is below a threshold (0.05 is the default, but can be changed using the `p.value` argument), we can reject the null hypothesis that characters are normally distributed. The default behaviour is to print only *`normally distributed`* or *`NOT normally distributed`* as result, but setting `p.value = NA` displays the exact p-values.


```{r include=F}
options(max.print = 30)
```
```{r echo = TRUE, eval=TRUE}
shapiroWilkTest(centaurea)

```

As the results are rather extensive (depending on number of groups and characters), they can be set assigned an object and exported  to the clipboard or file using the `exportRes()` function. This function is designed to export the spreadsheet-like results. If needed, default decimal separator (`dec`) and column delimiter character (`sep`) can be changed by particular arguments. See `exportRes()` documentation for details.  

```{r echo = TRUE, eval=FALSE}
swTest = shapiroWilkTest(centaurea)
exportRes(swTest, file = "clipboard")
exportRes(swTest, file = "D:/Projects/Centaurea_PSE/dataAnalysis/shapiroWilkTest.txt")
```

### 3.2.2 Histograms  

The histograms are a traditional way of displaying the shape of the distribution of data. Function `histCharacter()` displays a within-group distribution of each taxon for particular character. A density curve smoothing out the histogram (black) and the normal distribution curve (red) are drawn as default but can be removed using `densityLine = FALSE`, and `normDistLine = FALSE` arguments. Missing data are omitted.  

```{r echo = TRUE, eval=TRUE, out.width = '320px'}
histCharacter(centaurea, character = "SF")
```


To plot histograms for all characters with default settings to a new folder (in the working directory) use `histAll()` function.

```{r echo = TRUE, eval=FALSE}
histAll(centaurea, folderName = "histograms")
```



### 3.2.3 Normal Q-Q plot  

The normal Q-Q plot is another graphical method of assessing normality. The points should lie as close to the line as possible with no obvious pattern coming away from the line. Deviations from this line correspond to various types of non-normality.

Function `qqnormCharacter()` draws Q-Q plot for each taxon for a particular character, function `qqnormAll()` do the same for all of the characters (and save images to a new folder). Missing data are omitted.  


```{r echo = TRUE, eval=TRUE, out.width = '420px', out.height= '300px'}
qqnormCharacter(centaurea, character = "SF")
```


```{r echo = TRUE, eval=FALSE}
qqnormAll(centaurea, folderName = "qqnormPlots")
```



***

The most of the characters in the centaurea dataset does not have normal distribution. In general, there are two options: 
the distribution of data can be improved by transformation to make it more like normal, or nonparametric methods that do not require normality of distribution (Spearman's correlation coefficient instead of Pearson's, and k-nearest neighbours classificatory discriminant analysis instead of linear or quadratic DA) can be preferred.  

Transformation of data is the matter of the next section, but in all of the subsequent analysis, the original data will be used and nonparametric methods preferred.  

## 3.3 Data transformation

The characters that deviate most from the normal distribution can be transformed to improve their distribution (to become normally distributed or at least to achieve lower deviation from normality). From the wide palette of applicable transformations (e.g., logarithmic, square root, cube root, arcsine) the one which improves the distribution of a particular character the most should be chosen. Note that, when using a log transformation, a constant should be added to all values to make them all positive before transformation if there are zero values in the data, because the argument of the logarithm can be only positive numbers. The arcsine transformation is often used for proportions and percentages (for values ranging from 0 to 1).  

Transformation can be done by `transformCharacter()` function, which in addition to data, the name of the character which should be transformed (`character`), and new name of transformed character (`newName`; not required) takes as argument a `FUN`. The `FUN` is an Anonymous function (also known as a lambda expression), but without a long explanation, this is where to place the function that will transforms the data. Transformed data will replace original data, under the old or new name, if the `newName` argument was used.  
  
As the `transformCharacter()` takes as argument another function (`FUN` argument), there is an inexhaustible amount of potential transformations. Here we will mention some of them:  

For a right-skewed (positive) distribution can be used:  
* logarithmic transformation (natural): `FUN = function(x) log(100*x+1)`  
* logarithmic transformation (common): `FUN = function(x) log10(100*x+1)`  
* square root transformation: `FUN = function(x) sqrt(x)`   
* cube root transformation: `FUN = function(x) x^(1/3)`   
* arcsine transformation: `FUN = function(x) asin(sqrt(x))`  

For a left-skewed (negative) distribution can be used:   
* logarithmic transformation (natural): `FUN = function(x) log((100*max(x)+1)-x)`  
* logarithmic transformation (common): `FUN = function(x) log10((100*max(x)+1)-x)`  
* square root transformation: `FUN = function(x) sqrt((max(x)+1)-x)`    
* cube root transformation: `FUN = function(x) ((max(x)+1)-x)^(1/3)`    
* arcsine transformation: `FUN = function(x) asin(sqrt((max(x))-x))`  


As stated above, when using a log transformation, a constant should be added to all values to make them all positive before transformation. However, log transformation (together with changing the shape of the distribution) also changes multiplication to sum (the values differ x-times vs. differ by x). For small values of x, adding 1 significantly changes the original ratios, therefore, for log transformation of small numbers is recommended to multiply x by some constant (e.g. 100) at first, and then add 1, as is shown in examples above.  

The following figure depicts the effect of various transformation on the same data. 

```{r echo = FALSE, eval=TRUE, out.width = '420px', out.height= '300px'}
par(mfrow=c(2,2))
par(mar=c(4,4,2,1))
par(mgp=c(2,0.8,0))

centSquareRoot = transformCharacter(centaurea, character = "SF", FUN = sqrt)
centLog = transformCharacter(centaurea, character = "SF", FUN = function(x) log(x+1))
centCubeRoot = transformCharacter(centaurea, character = "SF", FUN = function(x) x^(1/3))



stats::qqnorm(as.matrix( na.omit(centaurea$data["SF"])), main = "original data", cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centaurea$data["SF"])), lwd=2)


stats::qqnorm(as.matrix( na.omit(centSquareRoot$data["SF"])), main = "sqrt transformed", cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centSquareRoot$data["SF"])), lwd=2)

stats::qqnorm(as.matrix( na.omit(centLog$data["SF"])), main = "log(x+1) transformed",cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centLog$data["SF"])), lwd=2)

stats::qqnorm(as.matrix( na.omit(centCubeRoot$data["SF"])), main = "x^(1/3) transformed", cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centCubeRoot$data["SF"])), lwd=2)



par(mfrow=c(1,1))
par(mgp=c(3, 1, 0))
par(mar=c(5, 4, 4, 2) + 0.1)

```

So finally, to apply square root transformation on character `SF`, the following code can be used.


```{r echo = TRUE, eval = FALSE}
centaurea = transformCharacter(centaurea, character = "SF", FUN = function(x) sqrt(x), 
                               newName = "SF.sqrt")
```




## 3.4 Box Plots

Boxplots are handy tools for detection of outlier values (potential typos, missing decimal points, etc.), between-species dissimilarities and critical morphological values discriminating among species.  

Boxplots can be calculated for a particular character using `boxplotCharacter()` or for all characters at once running `boxplotAll()` function, that saves all boxplots to a new folder in working directory (or to any location). The box is drawn from first to third quartile (25th - 75th percentiles), a horizontal line drawn inside denotes the median (50th percentile). The whiskers can be extended to desired percentiles using `lowerWhisker` and `upperWhisker` arguments. Missing data are omitted. Many graphic parameters can be set, run `?boxplotCharacter` for details. 

```{r echo = TRUE, eval=TRUE, out.width = '320px', out.height= '200px', dpi=300}
boxplotCharacter(centaurea, character = "AL", col = c("blue","green","red","orange"))
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', out.height= '200px', dpi=300}
boxplotCharacter(centaurea, character = "AL", lowerWhisker = 0.1, upperWhisker = 1, pch = 1)
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', out.height= '200px', dpi=300}
boxplotCharacter(centaurea, character = "AL", outliers = FALSE,
                 frame = FALSE, horizontal = T, notch = TRUE)
```


The default behaviour is to plot outliers (asterisks, can be changed by `pch` argument; `outliers = FALSE` will suppress plotting outliers) and to show the trimmed range (omitting 10% most extreme values) using whiskers.  

To plot boxplots for all characters with default settings to new folder (in the working directory):

```{r echo = TRUE, eval=FALSE}
boxplotAll(centaurea, folderName = "boxplots")
```



## 3.5 Descriptive statistics

The table of descriptive statistics is a less comfortable way of detecting outlier values, but it can be used for reporting descriptive statistics of morphological characters. This statistics can be calculated on the levels of populations, taxa/groups or for the whole dataset, using `descrPopulation()`, `descrTaxon()` or `descrAll()`, respectively. 


Using argument `format`, the desired output format can be specified. Keywords `$MEAN`, `$SD`, `$MIN`, `$5%`, `$25%`, `$MEDIAN`, `$75%`, `$95%`, `$MAX` will be replaced by actual values. The default behaviour (`format = NULL`) is to produces a table with all values. Run `?descrTaxon` for more details.

```{r echo = TRUE, eval=TRUE}
descrTaxon(centaurea, format = "($MEAN ± $SD)", decimalPlaces = 2)
```

The results can be assigned to an object and copied to the clipboard (fails for large data) or exported to file, both using the `exportRes()` function.
```{r eval=FALSE, include=TRUE}
descr_tax = descrTaxon(centaurea, format = "($MEAN ± $SD)", decimalPlaces = 2)
exportRes(descr_tax, file = "clipboard")
exportRes(descr_tax, file = "descr_tax.txt")
```

**KAROL:  toto sme vkladam**
Please note, that some of the following statistical analyses requires that no character can be invariant in any taxon. If it does, a more common practice is to add a small constant (e.g. 0.000001) to some value, than to remove the whole character.  

## 3.6 Correlations of characters

Highly correlated characters (r > |0.95|) should not be used in discriminant analysis, as this could potentially distort the results. Function `cormat()` calculates the correlation coefficients of the characters, Pearson’s (default) or Spearman’s (does not require normally distributed data). The results can be exported with the `exportRes()` function. One from the pair of highly correlated character can be removed from a dataset using `deleteCharacter()` function, see below.

```{r echo = TRUE, eval=FALSE}
correlations.s = cormat(centaurea, method = "spearman")
exportRes(correlations.s, file="correlations.spearman.txt")
```

Significance tests are usually unnecessary for morphometric analysis. Anyway, if tests are needed, they can be computed using the `cormatSignifTest()` function.

## 3.7 Populations as operational taxonomic units

To simplify the overall structure especially in large datasets, using populations instead of individuals can be considered. This means that each population will be represented by averages of the individuals' values. Missing values will be ignored.

```{r echo = FALSE, eval = TRUE}
populOTU <-function(object, crossval="indiv"){
cat("Warning: Unable to calculate the means of characters AL AW ALW AP in
populations LIP PREL. Values are NA.")
}
```
```{r echo = TRUE, eval=TRUE}
pops = populOTU(centaurea)
```
```{r echo = FALSE, eval = TRUE}
rm(populOTU)
```
```{r echo = FALSE, eval=TRUE, warning=FALSE}
defaultW <- getOption("warn")
options(warn = -1)
pops = populOTU(centaurea)
options(warn = defaultW)
```

There is a warning that the values of some characters are NA. How to deal with missing data, will be discussed in the following section.


## 3.8 Missing data

Missing values are not accepted in majority of the morphological analyses, and MorphoTools2 do not edit user's data in the background. The user has to do his/her own decision, what to do with missing values. There are two options: remove or replace. But before doing anything else, let's have a look at the descriptive statistic about missing data using `missingCharactersTable()` and `missingSamplesTable()` functions. The amount of missing data can be summarized on various levels, namely "`taxon`", populations ("`pop`"), or individuals ("`indiv`"). 

```{r include=F}
options(max.print = 800)
centaurea = deletePopulation(centaurea, populationName = c("BRT", "CERV", "CZLE", "DOM", "HVLT", "KASH", "KRO", "MIL", "NSED", "OLE1", "OLE2", "PRIS",  "PROS", "SOK", "STGH"))
```
```{r echo = TRUE, eval=TRUE}
# for demonstration only. Not all populations are displayed.
missingCharactersTable(centaurea, level = "pop")
```



```{r include=F}
centaurea$data = centaurea$data[-seq(4,10,1)]
```

```{r echo = TRUE, eval = TRUE}
# for demonstration only. Not all populations and morphological characters are displayed.
missingSamplesTable(centaurea, level = "pop")
```

```{r include=F}
data("centaurea")
options(max.print = 60)
```


As previous warnings indicated, populations LIP and PREL have the highest percentage of missing values in morphological characters (16%; 80 values per population are missing). The latter table shows that characters AL, AW, ALW, and AP are completely missing in these populations and 95% samples of population KOZH lack values of these characters.

### 3.8.1 Removing items

Previous descriptive tables showed that four characters in two populations are completely missing. User should decide between deleting characters using `deleteCharacter()` or populations using `deletePopulation()` function. As character AP looks promising for delimitation of *C. pseudophrygia* and *C. stenolepis*, characters will be keeped and the populations removed.

```{r echo = TRUE, eval=TRUE}
centaurea = deletePopulation(centaurea, populationName = c("LIP", "PREL"))
pops = deletePopulation(pops, populationName = c("LIP", "PREL"))
```

Another available option is to delete samples with a high portion of missing data using `deleteSample()` function. Command `deleteSample(centaurea, missingPercentage = 0.1)` will return a new `morphodata` object (dataset) where only samples having no more than 10% of missing data were retained. To remove specific samples, enumerate them in 'sampleName' argument in these functions.  

Here is the right place to mention also `deleteTaxon()` and another quartet of functions with reversed logic  which will return only mentioned samples, populations, taxa or characters: `keepSample()`, `keepPopulation()`, `keepTaxon()`, and `keepCharacter()`.

### 3.8.2 Replace missing values    

Missing values can be substituted by the average value of the respective character in the respective population. However, the mean substitution introduces values that are not present in the original dataset. This approach is acceptable only if: there are relatively few missing values; these missing values are scattered throughout many characters (each character includes only a few missing values); removing all individuals or all characters with missing data would unacceptably reduce the data set. To substitute remaining missing values by average value, use function `naMeanSubst()`.

```{r echo = TRUE, eval=TRUE}
centaurea = naMeanSubst(centaurea)
```


***
After examination of normality of distribution of each character, confirming that data do not contain highly correlated characters, replacing missing values by the average values, and removing remaining NAs, centaurea dataset is prepared for further analyses. It is not a bad idea to save a copy of it using `exportRes()` function. 




\newpage

# 4. Hierarchical clustering

Hierarchical classification is one of the methods that do not require *a priori* specification of the samples' membership in taxa (groups). Therefore, this method is recommended to use first to be able to get an insight into the existence of (hierarchical) group structure in data. Both individuals and populations can be used, but in large datasets (hundreds of specimens or more) the dendrograms for individuals may be somewhat messy and populations are better choice. Various measures of distance between the observations (rows) are applicable: (1) coefficients of distance for quantitative and binary characters: Euclidean (default), Manhattan, Minkovski; (2) similarity coefficients for binary characters: Jaccard and simple matching; (3) coefficient for mixed data: Gower. Clustering methods based on above coefficients are: UPGMA (default), Ward's method, single linkage, complete linkage, WPGMA, WPGMC, or UPGMC. However, note that for morphometric analysis Euclidean distance and UPGMA or Ward’s method are mostly used. The function includes standardization of the characters to a zero mean and a unit standard deviation. For further details, run `?clust`.  

The dendrogram is displayed using `plot()` function with usual graphical parameters. The parameter `hang` controls distance of the labels from the plot, negative values causing labels aligned at zero.

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300,}
pops_hierClust = clust(pops, distMethod = "euclidean", clustMethod = "UPGMA")
plot(pops_hierClust, hang = -1, sub = "", xlab = "", ylab = "distance")
```

Four main clusters were formed in the histogram above, however, some populations (BABL, LES, OLE1, OLE2, and PROS) were “incorrectly” clustered, what will require further inspection.



\newpage

# 5. Principal component analysis (PCA)

Principal component analysis (PCA) is another method without the requirement of *a priori* specification of the samples' membership in taxa (groups). PCA transforms the measured variables into principal components (artificial variables). The first few of them extract most of the variance in the measured variables. The standardized PCA based on correlation matrix is calculated by `pca.calc()` function (based on package `stats`; R Core Team, 2020), the result is an object of class `pcadata`. Run `?pcadata` for the help page about the elements of this object. Note the limitation of PCA with regard to the number of analyzed characters. It should be lower than the number of analyzed objects.


```{r echo = TRUE, eval=TRUE}
pca.centaurea = pca.calc(centaurea)
```


The summary statistics of the data is available using the function `summary()`. The eigenvalues indicate the proportion of variation of the original dataset expressed by individual axes, usually are presented as a percentage of their total sum (eigenvalues as percent). The eigenvectors express the direction of vectors characterizing the influence of the original characters on the principal component axes. The output of summary() function is usually truncated. To get a full listing, execute a `pca.centaurea$eigenValues`, `pca.centaurea$eigenvaluesAsPercent`, `pca.centaurea$cumulativePercentageOfEigenvalues`, and `pca.centaurea$eigenVectors` (values will be printed to console).


```{r echo = TRUE, eval=TRUE}
summary(pca.centaurea)
```

The result can be plotted by `plotPoints()` function. The parameter `axes` define principal components to plot (1st and 2nd being default) and `col` and `pch`[^4] control colour and type of plotting character, respectively (the same for each points or specific for each group (Taxon)). Usual graphical parameters control axes, size of point, etc., several parameters define the appearance and position of a legend; see `plotPoints()` documentation for details.  

&nbsp;  



[^4]: **Plotting symbols commonly used in R**  
![](./pch.png){width=100%}



```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), axes = c(1, 2),
           pch = c(8,17,20,18), legend = T, ncol = 2, legend.pos="bottomright")

```


The coordinates of the individuals (populations) on the principal components (sample scores) are stored in `pca.centaurea$objects$scores` and can be exported by `exportRes()` function. The dollar sign (`$`) enables one to extract items from a object, same as above.

```{r echo = TRUE, eval=FALSE}
exportRes(pca.centaurea$objects$scores, file="scoresPCA.centaurea.txt")
```

The character loadings (eigenvectors) express the influence of the original characters to the main components. Eigenvectors are stored in `pca.centaurea$eigenVectors` and can be exported by `exportRes()` function.
Function `plotCharacters()` draws character loadings as arrows. 


```{r echo = TRUE, eval=TRUE, out.width = '220px', fig.height = 6.5, dpi=300}
plotCharacters(pca.centaurea, cex = 1.2)

```
```{r echo = TRUE, eval=FALSE}
exportRes(pca.centaurea$eigenVectors, file="eigenVectors.centaurea.txt")

```

Ordination diagrams of PCA showed relatively compact groupings corresponding to taxa with partial overlaps. First two components (axes) extracted 20.65% and 14.26% of the overall variability in data. Characters ILW, IW, are strongly correlated with the direction of separation of taxa *C. pseudophrygia*, *C. stenolepis* (“ps”, “st”) and their putative hybrid “hybr”. The *C. phrygia* s.str. ("ph") is separated in the diagonal direction, highly correlated with MW, ML, IV, and MLW characters.

The `plotPoints()` and `plotCharacters()` are a default plotting functions. Simple point's labels and legend can be added using argument `labels = TRUE` and `legend = TRUE`, respectively. 


For more precise control of labels and legend, or adding additional elements to plot, the following functions can be used:  

* `plotAddLabels.points()`, `plotAddLabels.characters()` allows to include or exclude specified labels (`include`), specify the label's position (`pos`), offset (`offset`), colours (`col`), magnification (`cex`), etc.

* `plotAddLegend()` allows to specify position using keyword (`x`[^5]), number of columns (`ncol`), expansion and interspacing factors (`cex`, `pt.cex`, `x.intersp`, `y.intersp`), line width (`lwd`), borders parameters (e.g., `box.type`, `box.lty`, `box.lwd`), etc.

* `plotAddEllipses()` draws prediction ellipses around taxa. Ellipses with given probability (`probability`) define the regions where will fall any new independent observation from the respective taxa.

* `plotAddSpiders()` connects points with its group centroid, thus forms a "spider" diagram.


[^5]: **legend position**: `"topleft"`, `"topright"`, `"bottomleft"`, `"bottomright"`, `"top"`, `"left"`, `"bottom"`, `"right"`, and `"center"`.





```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
pca.pops = pca.calc(pops)

plotPoints(pca.pops, col = c("blue","green","red","orange"), pch = c(8,17,20,18), 
            legend = F, labels = F)

plotAddLabels.points(pca.pops, labels = c("PROS","SOK","KASH","BOL","KRO","DUB","MIL",
                      "CERM","DOM" ,"KOZH","KOT"), include = FALSE, pos = 4, cex=0.7)
plotAddLabels.points(pca.pops, labels = c("PROS","SOK","KASH","BOL","CERM", "DOM"), 
                      pos = 2,cex = 0.75)
plotAddLabels.points(pca.pops,labels=c("KRO","MIL","KOZH"),pos=3,offset=0.7,cex=0.75)
plotAddLabels.points(pca.pops,labels=c("DUB","KOT"), pos=1,offset=0.7, cex=0.75)
```


```{r echo = TRUE, eval=TRUE, out.width = '220px', fig.height = 6.5, dpi=300}
plotCharacters(pca.pops, labels = F)

plotAddLabels.characters(pca.pops, labels = c("ILW","MLW", "LBA"), pos = 4,cex = 0.75)
plotAddLabels.characters(pca.pops,labels=c("IW","SFT","MW"),pos=2,offset=0.7,cex=0.75)
```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), cex = 0.5)
plotAddLegend(pca.centaurea, col = c("blue","green","red","orange"), 
               x = "bottomright", pt.cex = 1.3, box.type = "n" ,ncol = 2)

# semi-transparent spider
plotAddSpiders(pca.centaurea, col = c(rgb(0,0,255,max=255,alpha=130), # blue
                                      rgb(0,255,0,max=255,alpha=130), # green
                                      rgb(255,0,0,max=255,alpha=130), # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```


To highlight only some groups, `NA` for other colours can be used.


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), cex = 0.5)

plotAddSpiders(pca.centaurea, col = c(NA, # blue
                                      NA, # green
                                      NA, # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```




```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), cex = 0.7)
plotAddLegend(pca.centaurea, col = c("blue","green","red","orange"), 
               x = "bottomright", pt.cex = 1.3, box.type = "n", ncol = 2)

plotAddEllipses(pca.centaurea, col = c("blue","green","red","orange"), lwd = 2)
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, type = "n", xlim = c(-5,7.5), ylim = c(-5,4))

plotAddEllipses(pca.centaurea, col = c("blue","green","red","orange"), lwd = 2)

plotAddLegend(pca.centaurea, col = c("blue","green","red","orange"), 
              x = "bottomright", pt.cex = 1.3, box.type = "n", ncol = 2)
```

To draw a 3D scatterplot, the `plot3Dpoints()` function can be used. The `theta` and `phi` arguments defines viewing direction (azimuthal direction and co-latitude, respectively).

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(pca.centaurea, col = c("blue","green","red","orange"), phi = 20, theta = 30)
```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(pca.pops, col = c("blue","green","red","orange"), labels = T )
```





\newpage

# 6. Principal coordinate analysis (PCoA)

Principal coordinate analysis (PCoA) is another method to explore and to visualize similarities or dissimilarities within the data. This method is especially useful in analysis of non-quantitative characters, when Euclidean distance and the corresponding measures of correlation do not provide acceptable model, so that the PCA is not adequate for ordination. PCoA estimates coordinates for a set of objects (rows) in a space, whose relationships are measured by any coefficient of similarity or distance (one of: Euclidean, Manhattan, Minkovski, Jaccard, simple matching, or Gower). PCoA might be used also in the case when there are more characters than objects in the analysis. As the PCoA is computed from distances among objects, therefore there is no direct information on the influence of original characters on coordinate axes.


The PCoA is calculated by `pcoa.calc()` function (based on package `stats`; R Core Team, 2020), the result is an object of class `pcoadata`.


```{r echo = TRUE, eval=TRUE}
pcoa.res = pcoa.calc(centaurea, distMethod = "manhattan")
summary(pcoa.res)
```





The result can be plotted by `plotPoints()` or `plot3Dpoints()` functions as per usual, extending methods (`plotAddEllipses()`, `plotAddSpiders()`, `plotAddLabels.points()`, and `plotAddLegend()`) are applicable as well. Only `plotCharacters()` function is not applicable, as there is no information on the influence of original characters on coordinate axes.

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(pcoa.res, col = c("blue","green","red","orange"), pch = c(8,17,20,18), 
             phi = 20, theta = 70, legend = T)
```


&nbsp;  




\newpage

# 7. Non-metric multidimensional scaling (NMDS)

All of the clustering analyses above attempt to preserve the distance relationships among the objects as much as possible. The main difference of the Non-metric multidimensional scaling (NMDS) is, that the preservation of distances is not of primary importance. This analysis is attempting to represent the objects in a small (usually two or three) number of dimensions (specified by `k` argument), preserving the order of distances among objects (similar objects are plotted closer to one another and dissimilar objects far apart).
Like principal coordinate analysis (PCoA), NMDS is not limited to Euclidean distance; it can produce ordinations using any coefficient of similarity or distance.

As NMDS compress the relationships among objects into two or three dimensions, this compression creates a "stress". The stress value can be interpreted as the "goodness" of the solution, where lower is better. Since stress decreases as dimensionality increases, the optimal solution is when the decrease in stress is small after decreasing the number of dimensions. Further, multiple runs of the NMDS analysis are needed to ensure that the stable ordination has been reached, as anyone run may get "trapped" in local optima which are not representative of true similarities.
Similarly to the PCoA, influence of original characters on new axes can not be directly derived. Moreover, axes of the ordination are arbitrary, thus the variation explained by individual axes is unknown.

The NMDS is calculated by `nmds.calc()` function (using the `monoMDS()` function from package `vegan`; R Core Team, 2020), the result is an object of class `pcoadata`.

The result can be plotted by `plotPoints()` or `plot3Dpoints()` functions, methods `plotAddEllipses()`, `plotAddSpiders()`, `plotAddLabels.points()`, and `plotAddLegend()` works as usual. Only `plotCharacters()` function is not applicable, as there is no information on the influence of original characters on coordinate axes.

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
nmds.res = nmds.calc(centaurea, distMethod = "euclidean", k = 3)
summary(nmds.res)
plotPoints(nmds.res, col = c("blue","green","red","orange"), pch = c(8,17,20,18), 
            legend = T)
```


&nbsp;  





\newpage

# 8. Stepwise discriminant analysis

In some analyses, a number of characters can not overcome a number of samples. If it does, only a subset of the "best" characters (contributing the most to the differentiation of predefined groups (taxa)) have to be selected. Another common requirement is linear independence of characters. Character should not be a linear combination of any other character(s). The way to eliminate such unnecessary or redundant characters is the use of a stepwise discriminant analysis.  

The most useful characters are identified and added to the selection step by step. After adding a new character, the significance of all the characters in the model is tested, and those which unique contribution is no more significant (bellow `F_to_stay` treshold) are excluded before addtion of the next most useful character. When none of the unselected variables meets the entry criterion (significance of their unique contribution is bellow `F_to_enter` treshold), or the maximum number of characters (depending on the number of individuals and defined groups) is reached, the selection process stops. After the final step, selected characters are printed to console, ordered according their importance for separation of the predefined groups.  

The stepwise discriminant analysis is calculated by `stepdisc.calc()` function.


```{r include=F}
options(max.print = 260)

```

```{r echo = TRUE, eval=TRUE}
stepdisc.calc(centaurea)
```

```{r include=F}
options(max.print = 60)

```





\newpage

# 9. Canonical discriminant analysis (CDA)

The Canonical discriminant analysis finds linear combinations of the original variables that provide maximal separation among *a priori* defined groups (by `Taxon` column in input data). The group membership should be defined using some independent data, i.e. other than morphology itself (such as ploidy levels, geographic origin, or genetic groups), to avoid circular reasoning.  

**KAROL: TUTU TO PISEM VSEOBECNE, lebo neskor sa k tomu vraciame pri classif DA**  
Discriminant analyses (in general) have requirements concerning number, correlation and variability of characters: (1) no character can be a linear combination of any other character; (2) no pair of characters can be highly correlated; (3) no character can be invariant in any taxon (group); (4) for the number of taxa (g), characters (p) and total number of samples (n) should hold: 0 < p < (n - g), and (5) there must be at least two groups (taxa), and in each group there must be at least two objects.  

The CDA analysis is used to find to what extent the predefined groups of objects can be distinguished based on available characters, and to identify characters, which mostly contribute to this differentiation. Note that the Canonical discriminant analysis finds n-1 canonical axes, where n is a number of groups (taxa). If two groups are analyzed, only a single axis is computed and the sample scores are displayed as a histogram.  

CDA can be calculated by `cda.calc()` function (using the `candisc` package; Friendly & Fox, 2020). A result is an object of class `cdadata`, and among other elements (run `?cdadata` for details) it stores total canonical structure coefficients, i.e., total-sample correlations between the original variables and the canonical variates. Thus, these coefficients are used to interpret the character's contribution to group separation. The function `summary()` print summaries of the results of `cda.calc()` function (variation explained by individual axes, total canonical structure coefficients).


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
cda.centaurea = cda.calc(centaurea)

summary(cda.centaurea)

plotPoints(cda.centaurea, col = c("blue","green","red","orange"), axes = c(1, 2),
           pch = c(8,17,20,18), legend = T, ncol = 2, legend.pos="bottomright")


```

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.centaurea, col = c(NA, "green", NA, NA), cex = 0.8)
plotAddSpiders(cda.centaurea, col = c(rgb(0,0,255,max=255,alpha=130), # blue
                                      NA, # green
                                      rgb(255,0,0,max=255,alpha=130), # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.centaurea, col = c(NA, "green", NA, NA), cex = 0.8)
plotAddEllipses(cda.centaurea, col = c("blue", NA, "red", "orange"), lwd = 2)

```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.centaurea, col = c("blue","green","red","orange"), cex = 0.4)
plotAddEllipses(cda.centaurea, col = c("blue","green","red","orange"), lwd = 2)
plotAddSpiders(cda.centaurea, col = c(rgb(0,0,255,max=255,alpha=130), # blue
                                      rgb(0,255,0,max=255,alpha=130), # green
                                      rgb(255,0,0,max=255,alpha=130), # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```

The CDA ordination diagram unequivocally supports the morphological differentiation of *C. phrygia* s.str. ("ph") along the first axis.  

```{r echo = TRUE, eval=TRUE, out.width = '220px', fig.height = 6.5, dpi=300}
plotCharacters(cda.centaurea, cex = 1.2)
```

Function `plotCharacters()` called with object of class `cdadata` as argument visualise total canonical structure coefficients as arrows. Direction and length of arrows indicate characters' contribution to separation of groups. Characters ML, MLW, IV and MW are oriented in the direction of separation of *C. phrygia* s.str. ("ph"), thus these characters contributed the most significantly, which is in accordance with the results of PCA. 

The total canonical structure coefficients are one of the elements of the object of class `cdadata` and can be accessed by the `$` notation. The above mentioned characters (ML, MLW, IV and MW) received highest scores at the first canonical axis (regardless of plus or minus sign). Results can be exported using the `exportRes()` function. 



```{r include=F}
options(max.print = 100)
```
```{r echo = TRUE, eval=TRUE}
exportRes(cda.centaurea$totalCanonicalStructure, file = "centaurea_TCS.txt")

cda.centaurea$totalCanonicalStructure
```


&nbsp;  
&nbsp;  

A 3D scatterplot can be produced using the `plot3Dpoints()` function. 
Viewing direction and slope (co-latitude) can be set by `theta` and `phi` arguments, respectively.


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(cda.centaurea, col = c("blue","green","red","orange"), phi = 12, theta = 25)
```




***

To gain better insight into the differentiation among remaining taxa (*C. pseudophrygia*, *C. stenolepis* and their putative hybrid), these taxa will be analysed separately. The new subdataset (stPsHybr) will be created by removing *C. phrygia* from the original dataset. 


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
stPsHybr = deleteTaxon(centaurea, taxonName = "ph")

cda.stPsHybr = cda.calc(stPsHybr)

plotPoints(cda.stPsHybr, col = c("blue","red","orange"), pch = c(8,20,18), 
            legend = T, ncol = 2, legend.pos="bottomright")

cda.stPsHybr$totalCanonicalStructure
```

The first axis extract most of the variation. Characters correlated with this axis (IW, ILW, LS, MW, and MLW) are the most suitable for taxonomic delimitation of *C. pseudophrygia* (“ps”) and *C. stenolepis* (“st”), while their hybrid exhibit middle values in these particular characters. The characters correlated with the second axis (IV, ML, and LW) contributes to the separation of hybrid from parental species.




### Passive prediction of samples. 

Sometimes it is desirable to passively display (predict) the position of some samples in the canonical space formed by other samples. This approach is applicable for displaying the position of hybrids, type specimens, "atypical" populations (that could not be assigned reliably to any of the predefined groups), etc. Passive samples can be specified using `passiveSamples` argument (accepting both populations and taxa). These samples will be excluded from computing discriminant function, and only passively predicted in multidimensional space. 

Note that in the following example, in which hybrids are passively projected into the analysis of parental species, only two "active" groups are present, "ps" and "st". In such a case, there is only one canonical axis and the sample scores are displayed as a histogram instead of a scatterplot by the `plotPoints()` function. The additional parameter `breaks` allows to define the width of intervals (histogram columns). Also note use of semi-transparent colours to show the overlap of the groups. The colours are defined using `rgb()` function in which the argument `alpha` defines opacity, in the example below on a scale 0 (fully transparent) to 255 (solid).


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}

cda.stPs_passiveHybr = cda.calc(stPsHybr, passiveSamples = "hybr")

plotPoints(cda.stPs_passiveHybr, legend = T, breaks = 0.2,
                col = c(rgb(0,0,255, alpha=255, max=255), # blue
                        rgb(255,0,0, alpha=160, max=255), # red
                        rgb(255,102,0, alpha=160, max=255))) # orange, 
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.stPs_passiveHybr, breaks = 0.2,
                col = c(rgb(0,0,0, alpha=255, max=255), # hybr - black
                        rgb(255,255,255, alpha=80, max=255), # ps - white
                        rgb(255,255,255, alpha=80, max=255))) # st - white 
```






\newpage

# 10. Classificatory discriminant analysis

Classificatory discriminant analysis (based on packages `MASS` and `class`; Venables & Ripley, 2002) is used to classify observations (sample dataset) into known groups, using criteria (discriminant functions) based on other observations with known group membership (training dataset). The group membership should be defined using some independent data, i.e. other than morphology itself (such as ploidy levels, geographic origin, or genetic groups), to avoid circular reasoning. If a morphological character has to be used to define groups, it should be excluded from further analyses. The results than indicate whether the retained characters are able to separate the groups in addition to the defining character. Often, we do not have two independent datasets (training and sample). In that case, we use a cross validation procedure, in which part of the dataset is used for computing the criteria that are applied on the remaining observations and the procedure is repeated until all observations are classified. The default is leave-one-out cross validation (the criterion is based on n – 1 individuals, and applied for the individual left out) but it is also possible to use whole populations as leave-out units (as individuals from a population are not completely independent observations and may be morphologically closer to each other than to individuals from other populations). The cross-validation mode can be specified by argument `crossval` as `"indiv"` or `"pop"`  (the former, which is the default option, is applied in the example below). The resulting classification is then compared with the original (*a priori*) classification of individuals into groups. The result of classificatory DA is stored in an object of class `classifdata`. The `classif.matrix()` function formats the results of the above functions as a summary classification table of taxa, populations or individuals. The results (classification tables) can be exported using the `exportRes()` function.  

As stated above, discriminant analyses have some requirements: (1) no character can be a linear combination of any other character; (2) no pair of characters can be highly correlated; (3) no character can be invariant in any taxon (group); (4) for the number of taxa (g), characters (p) and total number of samples (n) should hold: 0 < p < (n - g), and (5) there must be at least two groups (taxa), and in each group there must be at least two objects. Canonical DA works reasonably well even if some of these requirements were violated, but Linear and Quadratic classificatory DAs are more strict in this respect (**KAROL, to o CDA je OK???**), which is reflected by warning or error messages.  

To fulfil these requirements, only a subset of characters will be used. 
Linearly independent characters were identified by Stepwise discriminant analysis (see above). Invariant characters within taxon can be identified by `descrTaxon()` function. If invariant characters are present, a more common practice is to add a small constant (e.g. 0.000001) to some value, than to remove the character as a whole.  

```{r include=F}
options(max.print = 460)
```
```{r echo = TRUE, eval=TRUE}
stepdisc.calc(centaurea)

partialCentaurea = keepCharacter(centaurea, c("MLW", "ML", "IW", "LS", "IV", "MW", "MF", 
                                    "AP", "IS", "LBA", "LW", "AL", "ILW", "LBS",
                                    "SFT", "CG", "IL", "LM", "ALW", "AW", "SF") )

descrTaxon(partialCentaurea, format = "$SD")

partialCentaurea$data[ partialCentaurea$Taxon == "hybr", "LM" ][1] = 0.000001
partialCentaurea$data[ partialCentaurea$Taxon == "ph"  , "IV" ][1] = 0.000001
partialCentaurea$data[ partialCentaurea$Taxon == "st"  , "LBS"][1] = 0.000001
```


If data have approximately normal distribution, Linear (LDA; `classif.lda()`) or Quadratic (QDA; `classif.qda()`) discriminant function can be used. Decision is based on the homogeneity of the within-group covariance matrices (tested by Box's M-test; `BoxMTest()`). LDA assumes equality of covariances among characters (the predictor variables). This assumption is relaxed with the QDA.  
Nonparametric k-nearest neighbours method (`classif.knn()`) can be used without making any assumptions about data distributions. 

```{r echo = TRUE, eval=TRUE}
BoxMTest(partialCentaurea)

```


The Box’s M test indicated that there is a significant difference in the covariance matrices among taxa (p-value < 0.001) and therefore, Quadratic DA is recommended.



## 10.1 Linear discriminant analysis (LDA)





```{r echo = TRUE, eval=TRUE}
classifRes.lda = classif.lda(partialCentaurea)

```



ak cheme len vysledok, je to OK


EFEKT lda variables are collinear  - no ze je ich tam vela, a nie je jasny jednoznacny prispevok vybratych znakov. lepsi je mensi model

More importantly, it makes the estimated coefficients impossible to interpret. If an increase in X1, say, is associated with an decrease in X2 and they both increase variable Y, every change in X1 will be compensated by a change in X2 and you will underestimate the effect of X1 on Y. In LDA, you would underestimate the effect of X1 on the classification.

If all you care for is the classification per se, and that after training your model on half of the data and testing it on the other half you get 85-95% accuracy I'd say it is fine.


This suggests just what the error message says: some of your variables are collinear. In other words, the elements of one vector are a linear function of the elements of another, such as
0, 1, 2, 3
3, 5, 7, 9
In this case, LDA can't differentiate their influences on the rest of the world.



The stepwise discriminant analysis is calculated by `stepdisc.calc()` function.



```{r echo = TRUE, eval=TRUE}
classif.matrix(classifRes.lda, level = "taxon")

classif.matrix(classifRes.lda, level = "pop")
```

The deta## Coefficients of linear discriminants:
##                     LD1       LD2
## Sepal.Length  0.5081196 -0.925690
## Sepal.Width   1.9631006 -1.206187
## Petal.Length -2.1214689  1.868896
## Petal.Width  -2.9806917 -3.850355



iled classification of populations is very useful, as it can reveal some atypical or incorrectly assigned populations. Most of the populations from the sample data are successfully classified (generally over 70% correct classifications and often 100%), but some populations (BABL, CERM, LES, OLE2, PROS) have a maximum of 65% of correct classifications. Moreover, almost all of them were “incorrectly” clustered by hierarchical classification, and positions of these populations in the PCA ordination plot are within clusters of different taxa. Such populations require further attention. For example, these results may indicate previously unrecognized hybridization.  


The results can be exported to the clipboard or file using the `exportRes()` function. In the example below, posterior probabilities of classification of an individual into each group are exported. 

```{r echo = TRUE, eval=FALSE}
classif_lda = classif.matrix(classifRes.lda, level = "indiv")
exportRes(object = classif_lda,
          file = "lda_classifMatrix.txt")
```



## 10.2 Quadratic discriminant analysis (LDA)

&nbsp;   
&nbsp;  
does not assume equal covariance matrices amongst the groups

Well, qda assumes real values (and not factors) in the explanatory 
variables. If you think it makes sense to ignore this assumption (and I 
doubt it makes sense), then the error message tells you there is a rank 
deficiency, i.e. some variables might be collinear.
Hence at least one of the covariance matrices cannot be inverted.


## 10.3 k-nearest neighbour classificatory DA

The **k-nearest neighbour** method classifies an individual according to the *a priori* classification of its k neighbours (by Euclidean distance) using a majority vote. As this method uses Euclidean distance, the characters are standardised to a zero mean and a unit variance. The cross-validation mode can be set as `"indiv"` or `"pop"`, in the same manner as above.

The optimal number of neighbours to consider is unknown, but it is empirically estimated from the data. The `knn.select()` searches for the optimal k for the given data set. The function can use two cross-validation methods (by individuals and populations) in a similar way as the classificatory discriminant analysis functions (the latter is used in the example below). The function compute the number of correctly classified individuals for k values from 1 to 30 and highlight the value with the highest success rate. Ties (i.e., when there are the same numbers of votes for two or more groups) are broken at random, and thus several iterations may yield different results. Therefore, the functions compute 10 iterations, and the average success rates for each k are used; the minimum and maximum success rates for each k are also displayed as error bars. Note that several k values may have nearly the same success rates; if this is the case, the similarity of iterations may also be considered. 


```{r echo = FALSE, eval = TRUE}
knn.select<-function(object, crossval="indiv"){
  k = as.numeric(1:30)
  ksel = matrix(c(419,419,419,419,419,419,419,419,419,419,416,434,420,407,418,423,426,423,413,417,441,442,438,441,440,440,443,441,439,442,446,447,455,447,446,443,445,435,445,444,457,458,457,459,457,458,456,461,458,462,455,457,452,456,455,459,454,459,451,464,460,458,462,455,461,459,459,458,459,460,458,458,460,463,458,456,461,465,456,464,462,461,458,457,459,460,460,458,461,460,464,459,463,461,460,464,462,462,459,463,457,456,461,459,459,455,458,458,458,458,459,464,466,465,464,458,460,462,462,460,462,461,460,460,462,464,462,463,464,461,460,462,462,464,461,460,460,458,460,463,464,467,467,465,466,466,468,466,470,466,459,460,456,463,457,458,457,458,464,457,456,455,458,459,459,454,455,455,456,457,452,458,454,460,457,456,458,459,453,453,456,457,459,456,457,458,457,454,455,453,450,454,455,451,455,452,452,451,455,454,455,453,455,453,456,454,454,455,454,454,454,455,453,453,453,454,450,452,450,455,454,453,455,455,457,455,455,455,453,455,458,455,454,455,456,457,454,455,457,455,459,460,458,458,457,455,458,460,458,460,458,461,459,460,461,459,459,456,457,458,461,463,461,461,460,463,461,460,459,459,456,455,455,457,454,458,457,454,456,456,453,450,451,453,456,451,453,456,450,456,451,449,453,452,450,449,450,451,448,450), byrow = T, ncol = 10)
  
  ksel = t(ksel)
  
  for (j in 1:10)
  {
    cat("Tested ", j*10, "% of Ks \n")
  }
  
  kselmean = apply(ksel, MARGIN = 2, FUN = mean)
  kselmax = apply(ksel, MARGIN = 2, FUN = max)
  kselmin = apply(ksel, MARGIN = 2, FUN = min)
  graphics::plot(kselmean,type="p",pch=16,xlab="K",ylab="correct classifications", ylim=c(min(kselmin),max(kselmax)))

  sapply(k[-1],function(x) graphics::arrows(x, kselmin[x], x, kselmax[x], code = 3, angle = 90, length = 0.07))

  cat("\nThe highest number of correct classifications is at k = 15)\n")
}
```



```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
knn.select(partialCentaurea, crossval = "pop")
```

The highest number of correct classifications is at k = 12, thus we set `k = 15` in the `classif.knn()` function (to classify individual according its 12 nearest neighbours).

```{r echo = TRUE, eval=TRUE}
classifRes.knn = classif.knn(partialCentaurea, crossval = "pop", k = 15)

classif.matrix(classifRes.knn, level = "taxon")
```

The results can be exported with the `exportRes()` function.

```{r echo = TRUE, eval=FALSE}
popClassifMatrix = classif.matrix(classifRes.knn, level = "taxon")

exportRes(popClassifMatrix, file = "clipboard")
```


## 10.4 Classification of sample based on an independent training set.


 `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()` `classifSample.qda()`



The another functions, `classifSample.lda()` and `classifSample.knn()` are designed to classify hybrid populations, type herbarium specimens, atypical samples, entirely new data, etc. Discriminant criterion is developed from the original (training) dataset and applied to the specific sample (set).  

&nbsp;  

Let's remove population PRIS and pretend that sample PRIS418 is a type herbarium specimen of *Centaurea pseudophrygia* and we want to show its similarity with other populations of the species (typically, we have only morphology for old herbarium collections while we have other data for recently studied populations – but to assess their taxonomic identity, we should compare them with types ). To classify PRIS418, run the following code:

```{r echo = TRUE, eval=TRUE}
trainingSet = deletePopulation(partialCentaurea, populationName = "PRIS")
typeSpecimen = keepSample(partialCentaurea, "PRIS418")

classifSample.lda(typeSpecimen, trainingSet)

```

The probability, that sample PRIS418 is *C. pseudophrygia* is over 90%. 






\newpage

# Further reading

A brief account of the multivariate methods used in taxonomy is given in:  

**Marhold K. (2011)**. Multivariate morphometrics and its application to monography at specific and infraspecific levels. In: Stuessy TF, Lack HW, eds. *Monographic plant systematics: fundamental assessment of plant biodiversity*. Ruggell: A.R.G. Gantner Verlag K. G., 73–99.  

For a detailed description of used methods see:

**Legendre P. & Legendre L. (2012)**. *Numerical Ecology*, 3rd English edn. Elsevier Science BV, Amsterdam.



&nbsp;  

Selection of papers employing the methods of multivariate morphometrics:

**Lihová J, Kudoh H, Marhold K. (2010).** Morphometric studies of polyploid *Cardamine* species (Brassicaceae) from Japan: solving a long-standing taxonomic and nomenclatural controversy. *Australian Systematic Botany* 23, 94-111. doi: 10.1071/sb09038

**Melichárková A, Španiel S, Marhold K, Hurdu BI, Drescher A, Zozomová-Lihová J. (2019)**. Diversification and independent polyploid origins in the disjunct species *Alyssum repens* from the Southeastern Alps and the Carpathians. *American Journal of Botany* 106, 1499-1518. doi: 10.1002/ajb2.1370

**Skokanová K, Hodálová I, Mereďa P, Slovák M, Kučera, J. (2019)**. The *Cyanus tuberosus* group (Asteraceae) in the Balkans: biological entities require correct names. *Plant Systematics and Evolution* 305, 569–596. doi: 10.1007/s00606-019-01576-4

**Šlenker M, Zozomová-Lihová J, Mandáková T, Kudoh H, Zhao Y, Soejima A, et al. (2018)**. Morphology and genome size of the widespread weed *Cardamine occulta*: how it differs from cleistogamic *C. kokaiensis* and other closely related taxa in Europe and Asia. *Botanical Journal of the Linnean Society* 187, 456-482. doi: 10.1093/botlinnean/boy030

**Španiel S, Marhold K, Passalacqua NG, Zozomová-Lihová J. (2011)**. Intricate variation patterns in the diploid-polyploid complex of *Alyssum montanum-A. repens* (Brassicaceae) in the Apennine Peninsula: Evidence for long-term persistence and diversification. *American Journal of Botany* 98, 1887-1904. doi: 10.3732/ajb.1100147

**Šrámková G, Kolář F, Záveská E, Lučanová M, Španiel S, Kolník M, et al. (2019)**. Phylogeography and taxonomic reassessment of *Arabidopsis halleri* - a montane species from Central Europe. *Plant Systematics and Evolution* 305, 885-898. doi: 10.1007/s00606-019-01625-y




# References

**Friendly M, Fox J. (2020)**. candisc: Visualizing Generalized Canonical Discriminant and Canonical
  Correlation Analysis. R package version 0.8-3. https://CRAN.R-project.org/package=candisc

**Klecka WR. (1980)**. *Discriminant analysis (No. 19)*. Sage University Paper Series on Quantitative Applications in the Social Sciences 07-019.

**Koutecký P. (2007)**. Morphological and ploidy level variation of Centaurea phrygia agg.(Asteraceae) in the Czech Republic, Slovakia and Ukraine. *Folia Geobotanica*, 42, 77-102.

**Koutecký P. (2015)**. MorphoTools: a set of R functions for morphometric analysis. *Plant Systematics and Evolution*, 301, 1115-1121.

**Koutecký P, Štěpánek J, Baďurová T. (2012)**. Differentiation between diploid and tetraploid Centaurea phrygia: mating barriers, morphology and geographic distribution. *Preslia* 84, 1-32.

**Shlens, J. (2014)**. A tutorial on principal component analysis. *ArXiv* preprint arXiv:1404.1100

**Thorpe RS. (1976)**. Biometric analysis of geographic variation and racial affinities. *Biological Reviews of the Cambridge Philosophical Society* 51, 407–425.

**Venables WN, Ripley BD. (2002)**. *Modern Applied Statistics with S, Fourth edition*. New York: Springer. 





```{r echo = FALSE, eval=TRUE}
# rm unwanted files
unlink("centaurea_TCS.txt")

```


