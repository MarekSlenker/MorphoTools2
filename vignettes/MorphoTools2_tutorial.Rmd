---
title: \vspace{-2.0cm} MorphoTools2 version 1.0.0 tutorial 
author: | 
  | **Marek Šlenker** \vspace*{0.5pc}
  | Slovak Academy of Sciences, Bratislava, Slovakia
  | &
  | Charles University, Prague, Czechia \vspace*{0.5pc}
  | *https://github.com/MarekSlenker/MorphoTools2*
  | *<marek.slenker@savba.sk>*
output:
  pdf_document: default

vignette: |
  %\VignetteIndexEntry{MorphoTools2_tutorial}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---
&nbsp;  
 

```{r, include = FALSE}
knitr::opts_chunk$set(
  highlight = TRUE,
  dpi = 300,
  collapse = TRUE,
  comment = "#>",
  rownames = FALSE, 
  fig.width   = 6,       # the width for plots created by code chunk
  fig.height  = 5,       # the height for plots created by code chunk
  fig.align   = 'center', # how to align graphics in the final doc. 'left', 'right', 'center'
  #fig.path    = 'figs/',  # file path to the directory where knitr shall store the graphics files
  strip.white = TRUE     # if FALSE knitr will not remove white spaces at the beg or end of code chunk
  #out.width='\\textwidth'
  )
```

```{=latex}
\renewcommand{\baselinestretch}{0.5}
\tableofcontents
\renewcommand{\baselinestretch}{1.0}\normalsize
```




# 1. Introduction

The package `MorphoTools2` is dedicated to multivariate analyses of morphological data. The needed tools are at the moment scattered over several R libraries. This package wraps available statistical and graphical tools and provides a comprehensive framework for control and manipulation of the input data, core statistical analysis and the wide palette of functions designed to visualize results, to make the workflow convenient and fast.


# 2. Obtaining and installing MorphoTools2 package

The R console and base system can be obtained at <http://www.r-project.org/>. Once R is installed, `MorphoTools2` can be installed and loaded by typing the following commands into the R console:


```{r eval=FALSE, include=TRUE}
install.packages(MorphoTools2)
library(MorphoTools2)

```
```{r include=FALSE, eval=TRUE}
library(MorphoTools2)
```

To get the latest version of `MorphoTools2` package, install it using the `devtools::install_github()` function from the `devtools` package.

```{r include=TRUE, eval=FALSE}
install.packages("devtools")
devtools::install_github("MarekSlenker/MorphoTools2")
```

If you quit and restart R, you will need to load it again (using the `library` function as shown above).

# 3. Data import, control and manipulation

## 3.1 Data import

As with any statistical software, the first task is import your raw data. Data can be imported from: (1) plain text files (tab, comma, or whitespace delimited, see below); (2) from Excel spreadsheets through the clipboard in Windows. Following structure of input data is required: 

* the first row contains variable names.
* the next rows contain individuals (samples, or any other kind of sampling units), single individual per row.
* the first three columns include unique identifiers for individuals, populations and taxa/groups, respectively. Columns have to be named as “ID”, “Population” and “Taxon”[^1].
* fourth and next columns stores morphological characters[^2].

[^1]: In case the **population level is missing or inapplicable** (e.g. more than one individual only in some populations and/or very low number of individuals per population), copy the values from the"ID" column to "Population" column; this will allow analysing such data by most methods but any analyses considering population level are meaningless.

[^2]: **The morphological characters** can be quantitative, binary (coded as 0/1), or multi-state ordered categorical (semiquantitative, rank-ordered) characters  (e.g., 1 = small, 2 = medium, 3 = large, where change from state 1 to 3 is more costly than change from 1 to 2). On the other hand, nonordered categorical (qualitative, nominal) characters (e.g. describing colour: 1 = red, 2 = green, 3 = blue) are not applicable in most of the analyses (e.g., principal component or discriminant analyses). If there is a reason to include such unordered multistate characters, these characters either have to be coded as binary characters, as follows: redFlowers (0/1), greenFlowers (0/1), blueFlowers (0/1), or, in some cases coefficients for mixed data (e.g., Gower coefficient) should be used.



| ID      	| Population 	| Taxon 	| SN   	| SF   	| ST   	| SFT  	| LL   	| LW  	| LLW  	|
|---------	|------------	|-------	|------	|------	|------	|------	|------	|-----	|------	|
| RTE1    	| RTE        	| hybr  	| 35.2 	| 23.6 	| 58.8 	| 0.4  	| 11.2 	| 3.9 	| 2.87 	|
| RTE2    	| RTE        	| hybr  	| 39   	| 11.8 	| 50.8 	| 0.23 	| 7.2  	| 2.6 	| 2.77 	|
| RUS112  	| RUS        	| hybr  	| 24.8 	| 23.4 	| 48.2 	| 0.49 	| 7.1  	| 2.8 	| 2.54 	|
| RUS113  	| RUS        	| hybr  	| 30   	| 25.5 	| 55.5 	| 0.46 	| 10.2 	| 3.7 	| 2.76 	|
| OLE1272 	| OLE1       	| ps    	| 48.6 	| 6.3  	| 54.9 	| 0.11 	| 8.6  	| 3.8 	| 2.26 	|
| OLE1273 	| OLE1       	| ps    	| 58.1 	| 10   	| 68.1 	| 0.15 	| 11.2 	| 3.7 	| 3.03 	|
| OLE1274 	| OLE1       	| ps    	| 30.7 	| 26.6 	| 57.3 	| 0.46 	| 7.9  	| 3.1 	| 2.55 	|
| STGH309 	| STGH       	| ps    	| 77.1 	| 15.5 	| 92.6 	| 0.17 	| 11.6 	| 3.9 	| 2.97 	|
| STGH310 	| STGH       	| ps    	| 35.6 	| 19.2 	| 54.8 	| 0.35 	| 9.5  	|     	| *NA* 	|


Use underscores (_) instead of spaces, and avoid special characters (e.g. punctuation marks). Missing values have to be represented as empty cells or by the text `NA` (not quoted).

In this tutorial, we will use the centaurea dataset, containing measurements of 25 morphological characters of three diploid species of the *Centaurea phrygia* complex: *C. phrygia* s.str. (abbreviated "ph"), *C. pseudophrygia* ("ps") and *C. stenolepis* ("st") and the putative hybrid of the last two species abbreviated as "hybr" (for details, see Koutecký, 2015). The centaurea dataset is built-in in this package. Execute command `data(centaurea)` to load this data to your workspace.

```{r eval = TRUE, echo = TRUE}
data(centaurea)
```


In general, morphological data can be imported using the `read.morphodata()` function, providing path to your data[^3]. Argument `dec` stands for the character used in the file for decimal separator, `sep` is a column delimiter character, usually whitespace `""`, comma `","` or tab `"\t"`. The default values are a dot and tab (`"\t"`), respectively, and these may be omitted from the function call. To read data from clipboard (select cells in the Excel spreadsheet, press Ctrl+C ), set `file = "clipboard"`.

[^3]: **Example dataset** in txt and xlsx formats are stored in the "extdata" directory of the MorphoTools2 package installation directory. To find the path to the package location run `system.file("extdata", package = "MorphoTools2")`.

```{r eval = FALSE, echo = TRUE}
centaurea = read.morphodata(file = "<PATH TO centaurea.txt>", dec = ".", sep = "\t")
```

```{r eval = FALSE, echo = TRUE}
centaurea = read.morphodata(file = "clipboard")
```


The dataset now exists as a `morphodata` object in R. The `morphodata` object, as well as other objects used later, is defined as a `list`. In R lists act as containers for data. Elements stored in `morphodata` object can be referenced by the `$` notation. Type `centaurea$` and press the tab key to see contained elements. Command `centaurea$Taxon` print values on R console. Run `?morphodata` to see what a `morphodata` object contains. 

Alternatively, the following commands display basic information about the dataset or show data in the data viewer.

```{r echo = FALSE, eval = TRUE}
summary<-function(object){
  cat("object of class \'morphodata\'\
- contains 33 populations
- contains 4 defined groups (taxa)

Populations: BABL, BABU, BOL, BRT, BUK, CERM, CERV, CZLE, DEB, DOM, DUB, HVLT, KASH,
 KOT, KOZH, KRO, LES, LIP, MIL, NEJ, NSED, OLE1, OLE2, PREL, PRIS, PROS, RTE, RUS,
 SOK, STCV, STGH, VIT, VOL
Groups (taxa): hybr, ph, ps, st\n")
}
```
```{r echo = TRUE, eval=TRUE, collapse=TRUE}
summary(centaurea)
```
```{r echo = FALSE, eval = TRUE}
rm(summary)
```

```{r include=F}
options(max.print = 60)
```
```{r echo = TRUE, eval=TRUE}
samples(centaurea)
```

```{r echo = TRUE, eval=TRUE}
populations(centaurea)
```

```{r echo = TRUE, eval=TRUE}
taxa(centaurea)
```

```{r echo = TRUE, eval=TRUE}
characters(centaurea)
```

```{r echo = TRUE, eval=FALSE}
viewMorphodata(centaurea)
```

## 3.2 Data control and manipulation

Raw data can contain errors (e.g., typos in numbers or decimal points) and missing values which should be corrected or removed. We should also consider removing significantly correlated characters, that could potentially distort the results of some of the multivariate analyses. An assessment of the normality of distribution of data is a prerequisite for some statistical tests. If this assumption is not met, we can try to improve distribution by transformation, or prefer nonparametric methods that do not require normality of distribution of data.  
The following steps go through these issues and end up with the cleaned data ready for exploring the morphological differentiation among the taxa (or any defined groups).

### 3.2.1 Assessing whether the data follow normal distribution

An assessment whether the data follow normal distribution is a prerequisite for many statistical tests, but on the other hand, many analyses are quite robust to moderate deviations from normality. From the here used analyses, normality of distribution is required by Pearson correlation coefficient and Discriminant analysis (both canonical and linear). The normality of distribution of data is not an assumption of the Hierarchical clustering, Principal component analysis, Principal coordinates analysis, nor Non-metric multidimensional scaling.  
There are two main methods of assessing normality: numerically or graphically. Please note, although all methods available in `MorphoTools2` package are presented here, there is no need to use all of these methods at once. What we need is only a brief summary of whether the data are normally distributed or not.    

#### 3.2.1.1 Shapiro-Wilk normality test  
&nbsp;  

The normality of distribution of each character on the level of taxon/group can be tested using the Shapiro-Wilk statistic. If the calculated p-value of a certain character is below a threshold (0.05 is the default, but can be changed using the `p.value` argument), we can reject the null hypothesis that characters are normally distributed. The default behaviour is to print only *`normally distributed`* or *`NOT normally distributed`* as result, but setting `p.value = NA` displays the exact p-values.


```{r include=F}
options(max.print = 30)
```
```{r echo = TRUE, eval=TRUE}
shapiroWilkTest(centaurea)

```

As the results are rather extensive (depending on number of groups and characters), they can be set assigned an object and exported  to the clipboard or file using the `exportRes()` function. This function is designed to export the spreadsheet-like results. If needed, default decimal separator (`dec`) and column delimiter character (`sep`) can be changed by particular arguments. See `exportRes()` documentation for details.  

```{r echo = TRUE, eval=FALSE}
swTest = shapiroWilkTest(centaurea)
exportRes(swTest, file = "clipboard")
exportRes(swTest, file = "D:/Projects/Centaurea_PSE/dataAnalysis/shapiroWilkTest.txt")
```

#### 3.2.1.2 Histograms  
&nbsp;  

The histograms are a traditional way of displaying the shape of the distribution of data. Function `histCharacter()` displays a within-group distribution of each taxon for particular character. A density curve smoothing out the histogram (black) and the normal distribution curve (red) are drawn as default but can be removed using `densityLine = FALSE`, and `normDistLine = FALSE` arguments. Missing data are omitted.  

```{r echo = TRUE, eval=TRUE, out.width = '320px'}
histCharacter(centaurea, character = "SF")
```


To plot histograms for all characters with default settings to a new folder (in the working directory):

```{r echo = TRUE, eval=FALSE}
histAll(centaurea, folderName = "histograms")
```



#### 3.2.1.3 Normal Q-Q plot  
&nbsp;  

The normal Q-Q plot is another graphical method of assessing normality. The points should lie as close to the line as possible with no obvious pattern coming away from the line. Deviations from this line correspond to various types of non-normality.

Function `qqnormCharacter()` draws Q-Q plot for each taxon for a particular character, function `qqnormAll()` do the same for all of the characters (and save images to a new folder). Missing data are omitted.  


```{r echo = TRUE, eval=TRUE, out.width = '420px', out.height= '300px'}
qqnormCharacter(centaurea, character = "SF")
```


To plot histograms for all characters with default settings to a new folder (in the working directory):

```{r echo = TRUE, eval=FALSE}
qqnormAll(centaurea, folderName = "qqnormPlots")
```



---

We find that most of the characters in our dataset does not have normal distribution. In general, we have two options: we might try a transformation to make the distribution of data more like normal or prefer nonparametric methods that do not require normality (Spearman's correlation coefficient instead of Pearson's, and k-nearest neighbours classificatory discriminant analysis instead of Linear DA). 


Transformation of data is the matter of the next section, but in all of the subsequent analysis, we will use original data and prefer nonparametric methods.

### 3.2.2 Data transformation

The characters that deviate most from the normal distribution can be transformed to improve their distribution (to become normally distributed or at least to achieve less deviation from normality). From the wide palette of applicable transformations (e.g., logarithmic, square root, cube root, arcsine) you should choose the one that improves the data the most. Note that, when using a log transformation, a constant should be added to all values to make them all positive before transformation if there are zero values in the data, because the argument of the logarithm can be only positive numbers. The arcsine transformation is often used for proportions and percentages (for values ranging from 0 to 1).  

Transformation can be done by `transformCharacter()` function, which in addition to data, the name of the character which should be transformed (`character`), and new name of transformed character (`newName`; not required) takes as argument a `FUN`. The `FUN` is an Anonymous function (also known as a lambda expression), but without a long explanation, this is where to place the function that will transforms the data. Transformed data will replace original data, under the old or new name, if the `newName` argument was used.  
  
As the `transformCharacter()` takes as argument another function (`FUN` argument), there is an inexhaustible amount of potential transformations. Here we will mention some of them:  

For a right-skewed (positive) distribution can be used:  
* logarithmic transformation (natural): `FUN = function(x) log(100*x+1)`  
* logarithmic transformation (common): `FUN = function(x) log10(100*x+1)`  
* square root transformation: `FUN = function(x) sqrt(x)`   
* cube root transformation: `FUN = function(x) x^(1/3)`   
* arcsine transformation: `FUN = function(x) asin(sqrt(x))`  

For a left-skewed (negative) distribution can be used:   
* logarithmic transformation (natural): `FUN = function(x) log((100*max(x)+1)-x)`  
* logarithmic transformation (common): `FUN = function(x) log10((100*max(x)+1)-x)`  
* square root transformation: `FUN = function(x) sqrt((max(x)+1)-x)`    
* cube root transformation: `FUN = function(x) ((max(x)+1)-x)^(1/3)`    
* arcsine transformation: `FUN = function(x) asin(sqrt((max(x))-x))`  


As stated above, when using a log transformation, a constant should be added to all values to make them all positive before transformation. However, log transformation (together with changing the shape of the distribution) also changes multiplication to sum (the values differ x-times vs. differ by x). For small values of x, adding 1 significantly changes the original ratios, therefore, for log transformation of small numbers is recommended to multiply x by some constant (e.g. 100) at first, and then add 1, as is shown in examples above.  

The following figure depicts the effect of various transformation on the same data. 

```{r echo = FALSE, eval=TRUE, out.width = '420px', out.height= '300px'}
par(mfrow=c(2,2))
par(mar=c(4,4,2,1))
par(mgp=c(2,0.8,0))

centSquareRoot = transformCharacter(centaurea, character = "SF", FUN = sqrt)
centLog = transformCharacter(centaurea, character = "SF", FUN = function(x) log(x+1))
centCubeRoot = transformCharacter(centaurea, character = "SF", FUN = function(x) x^(1/3))



stats::qqnorm(as.matrix( na.omit(centaurea$data["SF"])), main = "original data", cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centaurea$data["SF"])), lwd=2)


stats::qqnorm(as.matrix( na.omit(centSquareRoot$data["SF"])), main = "sqrt transformed", cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centSquareRoot$data["SF"])), lwd=2)

stats::qqnorm(as.matrix( na.omit(centLog$data["SF"])), main = "log(x+1) transformed",cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centLog$data["SF"])), lwd=2)

stats::qqnorm(as.matrix( na.omit(centCubeRoot$data["SF"])), main = "x^(1/3) transformed", cex = 0.9, bty="n")
stats::qqline(as.matrix( na.omit(centCubeRoot$data["SF"])), lwd=2)



par(mfrow=c(1,1))
par(mgp=c(3, 1, 0))
par(mar=c(5, 4, 4, 2) + 0.1)

```

So finally, but just for illustration (as we will prefer nonparametric methods), to apply square root transformation on character `SF`, use the following code.


```{r echo = TRUE, eval = FALSE}
centaurea = transformCharacter(centaurea, character = "SF", FUN = function(x) sqrt(x), 
                               newName = "SF.sqrt")
```




### 3.2.3 Box Plots

Boxplots are handy tools for detection of outlier values (potential typos, missing decimal points, etc.), between-species dissimilarities and critical morphological values discriminating among species.  

Boxplots can be calculated for a particular character using `boxplotCharacter()` or for all characters at once running `boxplotAll()` function, that saves all boxplots to a new folder in your working directory (or to any location). The box is drawn from first to third quartile (25th - 75th percentiles), a horizontal line drawn inside denotes the median (50th percentile). The whiskers can be extended to desired percentiles using `lowerWhisker` and `upperWhisker` arguments. Missing data are omitted. Many graphic parameters can be set, run `?boxplotCharacter` for details. 

```{r echo = TRUE, eval=TRUE, out.width = '320px', out.height= '200px', dpi=300}
boxplotCharacter(centaurea, character = "AL", col = c("blue","green","red","orange"))
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', out.height= '200px', dpi=300}
boxplotCharacter(centaurea, character = "AL", lowerWhisker = 0.1, upperWhisker = 1, pch = 1)
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', out.height= '200px', dpi=300}
boxplotCharacter(centaurea, character = "AL", outliers = FALSE,
                 frame = FALSE, horizontal = T, notch = TRUE)
```


The default behaviour is to plot outliers (asterisks, can be changed by `pch` argument, or use `outliers = FALSE` to suppress plotting outliers) and to show the trimmed range (omitting 10% most extreme values) using whiskers. As you can see in the above figures, hybrids contain one markedly different value, which will require examination.


To plot boxplots for all characters with default settings to new folder (in the working directory):

```{r echo = TRUE, eval=FALSE}
boxplotAll(centaurea, folderName = "boxplots")
```



### 3.2.4 Descriptive statistics

The table of descriptive statistics is a less comfortable way of detecting outlier values, but it can be used for reporting descriptive statistics of morphological characters. This statistics can be calculated on the levels of populations, taxa/groups or for the whole dataset, using `descrPopulation()`, `descrTaxon()` or `descrAll()`, respectively. Using argument `format`, you can specify the desired output format. Keywords `$MEAN`, `$SD`, `$MIN`, `$5%`, `$25%`, `$MEDIAN`, `$75%`, `$95%`, `$MAX` will be replaced by actual values. The default behaviour (`format = NULL`) is to produces a table with all values. Run `?descrTaxon` for more details.

```{r echo = TRUE, eval=TRUE}
descrTaxon(centaurea, format = "($MEAN ± $SD)", decimalPlaces = 2)
```

The results can be assigned to an object and copied to the clipboard (fails for large data) or exported to file, both using the `exportRes()` function.
```{r eval=FALSE, include=TRUE}
descr_tax = descrTaxon(centaurea, format = "($MEAN ± $SD)", decimalPlaces = 2)
exportRes(descr_tax, file = "clipboard")
exportRes(descr_tax, file = "descr_tax.txt")
```

### 3.2.5 Correlations of characters

Highly correlated characters (r > |0.95|) should not be used in discriminant analysis, as this could potentially distort the results. Function `cormat` calculates the correlation coefficients of the characters, Pearson’s (default) or Spearman’s (does not require normally distributed data). The results can be exported with the `exportRes()` function. One from the pair of highly correlated character can be removed from a dataset using `deleteCharacter()` function, see below.

```{r echo = TRUE, eval=FALSE}
correlations.s = cormat(centaurea, method = "spearman")
exportRes(correlations.s, file="correlations.spearman.txt")
```

Significance tests are usually unnecessary for morphometric analysis. Anyway, if tests are needed, they can be computed using the `cormatSignifTest()` function.

### 3.2.6 Populations as operational taxonomic units

To simplify the overall structure especially in large datasets, one can consider the use of populations instead of individuals. This means that each population will be represented by averages of the individuals' values. Missing values will be ignored.

```{r echo = FALSE, eval = TRUE}
populOTU <-function(object, crossval="indiv"){
cat("Warning: Unable to calculate the means of characters AL AW ALW AP in
populations LIP PREL. Values are NA.")
}
```
```{r echo = TRUE, eval=TRUE}
pops = populOTU(centaurea)
```
```{r echo = FALSE, eval = TRUE}
rm(populOTU)
```
```{r echo = FALSE, eval=TRUE, warning=FALSE}
defaultW <- getOption("warn")
options(warn = -1)
pops = populOTU(centaurea)
options(warn = defaultW)
```
We received a warning that the values of some characters are `NA`. How to deal with missing data, we will discuss in the following section.


### 3.2.7 Missing data

Missing values are not accepted in morphological analyses, and MorphoTools2 do not edit user's data in the background. The user has to do his/her own decision, what to do with missing values. There are two options: remove or replace. But before we do anything else, let's look at the descriptive statistic about missing data using `missingCharactersTable()` and `missingSamplesTable()` functions. The amount of missing data can be summarized on various levels, namely "`taxon`", populations ("`pop`"), or individuals ("`indiv`"). 

```{r include=F}
options(max.print = 800)
centaurea = deletePopulation(centaurea, populationName = c("BRT", "CERV", "CZLE", "DOM", "HVLT", "KASH", "KRO", "MIL", "NSED", "OLE1", "OLE2", "PRIS",  "PROS", "SOK", "STGH"))
```
```{r echo = TRUE, eval=TRUE}
# for demonstration only. Not all populations are displayed.
missingCharactersTable(centaurea, level = "pop")
```



```{r include=F}
centaurea$data = centaurea$data[-seq(4,10,1)]
```

```{r echo = TRUE, eval = TRUE}
# for demonstration only. Not all populations and morphological characters are displayed.
missingSamplesTable(centaurea, level = "pop")
```

```{r include=F}
data("centaurea")
options(max.print = 60)
```


As previous warnings indicated, populations LIP and PREL have the highest percentage of missing values in morphological characters (16%; 80 values per population are missing). The latter table shows that characters AL, AW, ALW, and AP are completely missing in these populations and 95% samples of population KOZH lack values of these characters.


#### Remove items  

As four characters in two populations are completely missing, the next step is to decide between deleting characters using `deleteCharacter()` or populations using `deletePopulation()` function. As character AP looks promising for delimitation of *C. pseudophrygia* and *C. stenolepis*, we will keep the characters and remove the populations.

```{r echo = TRUE, eval=TRUE}
centaurea = deletePopulation(centaurea, populationName = c("LIP", "PREL"))
pops = deletePopulation(pops, populationName = c("LIP", "PREL"))
```

Another available option is to delete samples with a high portion of missing data using `deleteSample()` function. Command `deleteSample(centaurea, missingPercentage = 0.1)` will return samples having no more than 10% of missing data. To remove specific samples, enumerate them in 'sampleName' argument in these functions.  

Here is the right place to mention also `deleteTaxon()` and another quartet of functions with reversed logic  which will return only mentioned samples, populations, taxa or characters: `keepSample()`, `keepPopulation()`, `keepTaxon()`, and `keepCharacter()`.

#### Replace missing values    

Missing values can be substituted by the average value of the respective character in the respective population. However, the mean substitution introduces values that are not present in the original dataset. This approach is acceptable only if: there are relatively few missing values; these missing values are scattered throughout many characters (each character includes only a few missing values); removing all individuals or all characters with missing data would unacceptably reduce the data set. To substitute remaining missing values by average value, use function `naMeanSubst()`.

```{r echo = TRUE, eval=TRUE}
centaurea = naMeanSubst(centaurea)
```


***
We examined outlier value in "hybr" group and ensured that data do not contain highly correlated characters. Populations containing only NAs in some characters were removed and remaining missing values were replaced by the average values. Our dataset is now prepared for further analyses. It is not a bad idea to save a copy of it using `exportRes()` function. 




# 4. Hierarchical clustering

Hierarchical classification is one of the methods that do not require *a priori* specification of the samples' membership in taxa (groups). Therefore, this method is recommended to use first to be able to get an insight into the existence of group structure in your data. Both individuals and populations can be used, but in large datasets (hundreds of specimens or more) the dendrograms for individuals may be somewhat messy and populations are better choice. Various measures of distance between the observations (rows) are applicable: (1) coefficients of distance for quantitative and binary characters: Euclidean (default), Manhattan, Minkovski; (2) similarity coefficients for binary characters: Jaccard and simple matching; (3) coefficient for mixed data: Gower. Clustering methods based on above coefficients are: UPGMA (default), Ward's method, single linkage, complete linkage, WPGMA, WPGMC, or UPGMC. However, note that for morphometric analysis hardly anything else is used than Euclidean distance and UPGMA or Ward’s method. The function includes standardization of the characters to a zero mean and a unit standard deviation. For further details, run `?clust`.  

The dendrogram is displayed using `plot` function with usual graphical parameters. The parameter `hang` controls distance of the labels from the plot, negative values causing labels aligned at zero.

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300,}
pops_hierClust = clust(pops, distMethod = "euclidean", clustMethod = "UPGMA")
plot(pops_hierClust, hang = -1, sub = "", xlab = "", ylab = "distance")
```

Four main clusters were formed in the histogram above, however, some populations (BABL, LES, OLE1, OLE2, and PROS) were “incorrectly” clustered, what will require further inspection.



# 5. Principal component analysis (PCA)

Principal component analysis (PCA) is another method without the requirement of *a priori* specification of the samples' membership in taxa (groups). PCA transforms the measured variables into principal components (artificial variables). The first few of them extract most of the variance in the measured variables. The standardized PCA based on correlation matrix is calculated by `pca.calc()` function (based on package `stats`; R Core Team, 2020), the result is an object of class `pcadata`. Run `?pcadata` for the help page about the elements of this object. 


```{r echo = TRUE, eval=TRUE}
pca.centaurea = pca.calc(centaurea)
```


The summary statistics of the data is available using the function `summary()`. The eigenvalues indicate the proportion of variation of the original dataset expressed by individual axes, usually are presented as a percentage of their total sum (eigenvalues as percent). The eigenvectors express the direction of vectors characterizing the influence of the original characters on the principal component axes. The output of summary() function is usually truncated. To get a full listing, execute a `pca.centaurea$eigenValues`, `pca.centaurea$eigenvaluesAsPercent`, `pca.centaurea$cumulativePercentageOfEigenvalues`, and `pca.centaurea$eigenVectors` (values will be printed to console).


```{r echo = TRUE, eval=TRUE}
summary(pca.centaurea)
```

The result can be plotted by `plotPoints()` function. The parameter `axes` define principal components to plot (1st and 2nd being default) and `col` and `pch`[^4] control colour and type of plotting character, respectively (the same for each points or specific for each group (Taxon)). Usual graphical parameters control axes, size of point, etc., several parameters define the appearance and position of a legend; see `plotPoints()` documentation for details.  

&nbsp;  



[^4]: **Plotting symbols commonly used in R**  
![](./pch.png){width=100%}



```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), axes = c(1, 2),
           pch = c(8,17,20,18), legend = T, ncol = 2, legend.pos="bottomright")

```


The coordinates of the individuals (populations) on the principal components (sample scores) are stored in `pca.centaurea$objects$scores` and can be exported by `exportRes()` function. The dollar sign (`$`), lets you access elements within an object, same as above.

```{r echo = TRUE, eval=FALSE}
exportRes(pca.centaurea$objects$scores, file="scoresPCA.centaurea.txt")
```

The character loadings (eigenvectors) express the influence of the original characters to the main components. Eigenvectors are stored in `pca.centaurea$eigenVectors` and can be exported by `exportRes()` function.
Function `plotCharacters()` draws character loadings as arrows. 


```{r echo = TRUE, eval=TRUE, out.width = '220px', fig.height = 6.5, dpi=300}
plotCharacters(pca.centaurea, cex = 1.2)

```
```{r echo = TRUE, eval=FALSE}
exportRes(pca.centaurea$eigenVectors, file="eigenVectors.centaurea.txt")

```

As you can see in the figures above, ordination diagrams of PCA showed relatively compact groupings corresponding to taxa with partial overlaps. First two components (axes) extracted 20.65% and 14.26% of the overall variability in data. Characters ILW, IW, are strongly correlated with the direction of separation of taxa *C. pseudophrygia*, *C. stenolepis* (“ps”, “st”) and their putative hybrid “hybr”. The *C. phrygia* s.str. ("ph") is separated in the diagonal direction, highly correlated with MW, ML, IV, and MLW characters.

The `plotPoints()` and `plotCharacters()` are a default plotting functions. You can add simple labels using argument `labels = TRUE`, or point's legend using `legend = TRUE`. If you need more precise control about plotting or want to add other elements to points, use some of the following functions:  

* `plotAddLabels.points()`, `plotAddLabels.characters()` allows you to include or exclude specified labels (`include`), specify the label's position (`pos`), offset (`offset`), colours (`col`), magnification (`cex`), etc.

* `plotAddLegend()` allows you to specify position using keyword (`x`[^5]), number of columns (`ncol`), expansion and interspacing factors (`cex`, `pt.cex`, `x.intersp`, `y.intersp`), line width (`lwd`), borders parameters (e.g., `box.type`, `box.lty`, `box.lwd`), etc.

* `plotAddEllipses()` draws prediction ellipses around taxa. Ellipses with given probability (`probability`) define the regions where will fall any new independent observation from the respective taxa.

* `plotAddSpiders()` connects points with its group centroid, thus forms a "spider" diagram.


[^5]: **legend position**: `"topleft"`, `"topright"`, `"bottomleft"`, `"bottomright"`, `"top"`, `"left"`, `"bottom"`, `"right"`, and `"center"`.





```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
pca.pops = pca.calc(pops)

plotPoints(pca.pops, col = c("blue","green","red","orange"), pch = c(8,17,20,18), 
            legend = F, labels = F)

plotAddLabels.points(pca.pops, labels = c("PROS","SOK","KASH","BOL","KRO","DUB","MIL",
                      "CERM","DOM" ,"KOZH","KOT"), include = FALSE, pos = 4, cex=0.7)
plotAddLabels.points(pca.pops, labels = c("PROS","SOK","KASH","BOL","CERM", "DOM"), 
                      pos = 2,cex = 0.75)
plotAddLabels.points(pca.pops,labels=c("KRO","MIL","KOZH"),pos=3,offset=0.7,cex=0.75)
plotAddLabels.points(pca.pops,labels=c("DUB","KOT"), pos=1,offset=0.7, cex=0.75)
```


```{r echo = TRUE, eval=TRUE, out.width = '220px', fig.height = 6.5, dpi=300}
plotCharacters(pca.pops, labels = F)

plotAddLabels.characters(pca.pops, labels = c("ILW","MLW", "LBA"), pos = 4,cex = 0.75)
plotAddLabels.characters(pca.pops,labels=c("IW","SFT","MW"),pos=2,offset=0.7,cex=0.75)
```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), cex = 0.5)
plotAddLegend(pca.centaurea, col = c("blue","green","red","orange"), 
               x = "bottomright", pt.cex = 1.3, box.type = "n" ,ncol = 2)

# semi-transparent spider
plotAddSpiders(pca.centaurea, col = c(rgb(0,0,255,max=255,alpha=130), # blue
                                      rgb(0,255,0,max=255,alpha=130), # green
                                      rgb(255,0,0,max=255,alpha=130), # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```


To highlight only some groups, use `NA` for other colours.


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), cex = 0.5)

plotAddSpiders(pca.centaurea, col = c(NA, # blue
                                      NA, # green
                                      NA, # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```




```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, col = c("blue","green","red","orange"), cex = 0.7)
plotAddLegend(pca.centaurea, col = c("blue","green","red","orange"), 
               x = "bottomright", pt.cex = 1.3, box.type = "n", ncol = 2)

plotAddEllipses(pca.centaurea, col = c("blue","green","red","orange"), lwd = 2)
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(pca.centaurea, type = "n", xlim = c(-5,7.5), ylim = c(-5,4))

plotAddEllipses(pca.centaurea, col = c("blue","green","red","orange"), lwd = 2)

plotAddLegend(pca.centaurea, col = c("blue","green","red","orange"), 
              x = "bottomright", pt.cex = 1.3, box.type = "n", ncol = 2)
```

A 3D scatterplot can be produced using the `plot3Dpoints` function. Use `phi` and `theta` arguments to define slope and viewing direction.

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(pca.centaurea, col = c("blue","green","red","orange"), phi = 20, theta = 30)
```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(pca.pops, col = c("blue","green","red","orange"), labels = T )
```




# 6. Principal coordinate analysis (PCoA)

Principal Coordinate Analysis (PCoA) is another method to explore and to visualize similarities or dissimilarities within the data. This method is especially useful in analysis of non-quantitative characters, when Euclidean distance and the corresponding measures of correlation do not provide acceptable model, so that the PCA is not adequate for ordination. PCoA estimates coordinates for a set of objects (rows) in a space, whose relationships are measured by any coefficient of similarity or distance (one of: Euclidean, Manhattan, Minkovski, Jaccard, simple matching, or Gower).
As the PCoA is computed from distances among objects, therefore, is no information on the influence of original characters on coordinate axes.


The PCoA is calculated by `pcoa.calc()` function (based on package `stats`; R Core Team, 2020), the result is an object of class `pcoadata`.


```{r echo = TRUE, eval=TRUE}
pcoa.res = pcoa.calc(centaurea, distMethod = "manhattan")
summary(pcoa.res)
```





The result can be plotted by `plotPoints()` or `plot3Dpoints()` functions as per usual, extending methods (`plotAddEllipses()`, `plotAddSpiders()`, `plotAddLabels.points()`, and `plotAddLegend()`) are applicable as well. Only `plotCharacters()` function is not applicable, as there is no information on the influence of original characters on coordinate axes.

```{r echo = TRUE, eval=TRUE}
plot3Dpoints(pcoa.res, col = c("blue","green","red","orange"), pch = c(8,17,20,18), 
             phi = 20, theta = 70, legend = T)
```


&nbsp;  






























# 7. Non-metric multidimensional scaling (NMDS)


The method of nonmetric multidimensional scaling (MDS, Section 9.3) also
obtains ordinations of objects from any resemblance matrix. It is better than principal
coordinate analysis at compressing the distance relationships among objects into, say,
two or three dimensions. By construction, MDS always obtains a Euclidean
representation, even from non-Euclidean-embeddable distances. MDS is, however, a
computer-intensive technique requiring far more computing time than PCoA. For large
distance matrices, principal coordinate analysis is faster in most cases.


The metric information in the data or distances is not preserved by the ordination. The method of non-metric multidimensional scaling considers the rank order of distances, rather than their actual magnitudes. The objective is to arrange the objects in a few (usually two) dimensions such that the rank order of distances in the new space follows the original rank order as closely as possible. The "goodness" of the non-metric solution is measured by the stress between the original and the new distances. The procedure is iterative, the initial configuration is random or read from disk file in form of data with objects as rows, in free format. You may start immediately requesting two dimensions; if you choose, say, 3 for start, the two-dimensional solution will be obtained from the three-dimensional. Maximum starting dimensionality is 5. A stress of 0.1-0.2 is considered fairly good, but there is no general rule since the stress is greatly influenced by the number of points. The Shepard diagram gives a visual comparison of original and new distances. In an ideal case the distances increase monotonically over the original distances. The worse the solution, the more scattered the points in the Shepard diagram. After computations, the ordination of objects and the Shepard diagram can be displayed.

NMDS is not limited to Euclidean distances, as PCA does

co stress plot?   to predpokladam nema zmysel























# 8. Canonical discriminant analysis (CDA)

The Canonical discriminant analysis finds linear combinations of the original variables that provide maximal separation among *a priori* defined groups (by `Taxon` column in input data). The group membership should be defined using some independent data, i.e. other than morphology itself (such as ploidy levels, geographic origin, or genetic groups), to avoid circular reasoning.  
The CDA analysis is used to find to what extent the predefined groups of objects can be distinguished based on available characters, and to identify characters, which mostly contribute to this differentiation. Note that the Canonical discriminant analysis finds n-1 canonical axes, where n is a number of groups (taxa). If two groups are analyzed, only a single axis is computed and the sample scores are displayed as a histogram.  

CDA can be calculated by `cda.calc()` function (using the `candisc` package; Friendly & Fox, 2020). A result is an object of class `cdadata`, and among other elements (run `?cdadata` for details) it stores total canonical structure coefficients, i.e., total-sample correlations between the original variables and the canonical variates. Thus, we use them to interpret the character's contribution to group separation. The function `summary()` print summaries of the results of `cda.calc()` function (variation explained by individual axes, total canonical structure coefficients).


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
cda.centaurea = cda.calc(centaurea)

summary(cda.centaurea)

plotPoints(cda.centaurea, col = c("blue","green","red","orange"), axes = c(1, 2),
           pch = c(8,17,20,18), legend = T, ncol = 2, legend.pos="bottomright")


```

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.centaurea, col = c(NA, "green", NA, NA), cex = 0.8)
plotAddSpiders(cda.centaurea, col = c(rgb(0,0,255,max=255,alpha=130), # blue
                                      NA, # green
                                      rgb(255,0,0,max=255,alpha=130), # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.centaurea, col = c(NA, "green", NA, NA), cex = 0.8)
plotAddEllipses(cda.centaurea, col = c("blue", NA, "red", "orange"), lwd = 2)

```


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.centaurea, col = c("blue","green","red","orange"), cex = 0.4)
plotAddEllipses(cda.centaurea, col = c("blue","green","red","orange"), lwd = 2)
plotAddSpiders(cda.centaurea, col = c(rgb(0,0,255,max=255,alpha=130), # blue
                                      rgb(0,255,0,max=255,alpha=130), # green
                                      rgb(255,0,0,max=255,alpha=130), # red
                                      rgb(255,102,0,max=255,alpha=130))) # orange
```


```{r echo = TRUE, eval=TRUE, out.width = '220px', fig.height = 6.5, dpi=300}
plotCharacters(cda.centaurea, cex = 1.2)
```


The CDA ordination diagram unequivocally supports the morphological differentiation of *C. phrygia* s.str. ("ph") along the first axis. Characters ML, MLW, IV and MW are oriented in the direction of separation, thus these characters contributed the most significantly, which is in accordance with the results of PCA. The values of correlation of characters with the first canonical axis (total canonical structure coefficients) are one of the elements of the object of class `cdadata` and can be accessed by the `$` notation. Results can be exported using the `exportRes()` function. 

```{r include=F}
options(max.print = 100)
```
```{r echo = TRUE, eval=TRUE}
exportRes(cda.centaurea$totalCanonicalStructure, file = "centaurea_TCS.txt")

cda.centaurea$totalCanonicalStructure
```

As you can see, the above mentioned characters (ML, MLW, IV and MW) received highest scores at the first canonical axis (regardless of plus or minus sign).   

&nbsp;  
&nbsp;  

To gain better insight into the differentiation among remaining taxa (*C. pseudophrygia*, *C. stenolepis* and their putative hybrid), we will analyze them separately. The new subdataset (stPsHybr) will be created by removing *C. phrygia* from the original dataset. 


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
stPsHybr = deleteTaxon(centaurea, taxonName = "ph")

cda.stPsHybr = cda.calc(stPsHybr)

plotPoints(cda.stPsHybr, col = c("blue","red","orange"), pch = c(8,20,18), 
            legend = T, ncol = 2, legend.pos="bottomright")

cda.stPsHybr$totalCanonicalStructure
```

The first axis extract most of the variation. Characters correlated with this axis (IW, ILW, LS, MW, and MLW) are the most suitable for taxonomic delimitation of *C. pseudophrygia* (“ps”) and *C. stenolepis* (“st”), while their hybrid exhibit middle values in these particular characters. The characters correlated with the second axis (IV, ML, and LW) contributes to the separation of hybrid from parental species.


&nbsp;  
&nbsp;  

To draw a 3D scatterplot, use the `plot3Dpoints` function. Slope and viewing direction can be set by `phi` and `theta` parameters.

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plot3Dpoints(cda.centaurea, col = c("blue","green","red","orange"), phi = 12, theta = 25)
```


---
#### Passive prediction of samples. 
Sometimes it is desirable to passively display (or predict) the position of some samples in the canonical space formed by other samples. This approach is applicable for displaying the position of hybrids, type specimens, "atypical" populations (that could not be assigned reliably to any of the predefined groups), etc. Passive samples can be specified using `passiveSamples` argument (accepting both populations and taxa). These samples will be excluded from computing discriminant function, and only passively predicted in multidimensional space. 

Note that in the following example, in which hybrids are passively projected into the analysis of parental species, only two "active" groups are present, "ps" and "st". In such a case, there is only one canonical axis and the sample scores are displayed as a histogram instead of a scatterplot by the `plotPoints()` function. The additional parameter `breaks` allows to define the width of intervals (histogram columns). Also note use of semi-transparent colours to show the overlap of the groups. The colours are defined using `rgb()` function in which the argument `alpha` defines opacity, in the example below on a scale 0 (fully transparent) to 255 (solid).


```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}

cda.stPs_passiveHybr = cda.calc(stPsHybr, passiveSamples = "hybr")

plotPoints(cda.stPs_passiveHybr, legend = T, breaks = 0.2,
                col = c(rgb(0,0,255, alpha=255, max=255), # blue
                        rgb(255,0,0, alpha=160, max=255), # red
                        rgb(255,102,0, alpha=160, max=255))) # orange, 
```

```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
plotPoints(cda.stPs_passiveHybr, breaks = 0.2,
                col = c(rgb(0,0,0, alpha=255, max=255), # hybr - black
                        rgb(255,255,255, alpha=80, max=255), # ps - white
                        rgb(255,255,255, alpha=80, max=255))) # st - white 
```





# 9. Classificatory discriminant analysis

Classificatory discriminant analysis (based on packages `MASS` and `class`; Venables & Ripley, 2002) is used to classify observations (sample dataset) into known groups, using criteria (discriminant functions) based on other observations with known group membership (training dataset). The group membership should be defined using some independent data, i.e. other than morphology itself (such as ploidy levels, geographic origin, or genetic groups), to avoid circular reasoning. If a morphological character has to be used to define groups, it should be excluded from further analysis. The results than indicate if the retained characters are able to separate the groups in addition to the defining character. Often, we do not have two independent datasets (training and sample). In that case, we use a cross validation procedure, in which part of the dataset is used for computing the criteria that are applied on the remaining observations and the procedure is repeated until all observations are classified. The default is leave-one-out cross validation (the criterion is based on n – 1 individuals, and applied for the individual left out) but it is also possible to use whole populations as leave-out units (as individuals from a population are not completely independent observations and may be morphologically closer to each other than to individuals from other populations). The cross-validation mode can be specified by argument `crossval` as `"indiv"` or `"pop"`  (the former, which is the default option, is applied in the example below). The resulting classification is then compared with the original (*a priori*) classification of individuals into groups. The result of classificatory DA is stored in an object of class `classifdata`. The `classif.matrix` function formats the results of the above functions as a summary classification table of taxa, populations or individuals. The results (classification tables) can be exported using the `exportRes()` function.  

Linear discriminant function (`classif.lda()`) can be used for data with approximately multivariate normal within-class distributions. Nonparametric k-nearest neighbours method (`classif.knn()`) can be used without making any assumptions about these distributions. 

```{r include=F}
options(max.print = 460)
```
```{r echo = TRUE, eval=TRUE}
classifRes.lda = classif.lda(centaurea)

classif.matrix(classifRes.lda, level = "taxon")

classif.matrix(classifRes.lda, level = "pop")
```

The detailed classification of populations is very useful, as it can reveal some atypical or incorrectly assigned populations. Most of the populations from the sample data are successfully classified (generally over 70% correct classifications and often 100%), but some populations (BABL, CERM, LES, OLE2, PROS) have a maximum of 65% of correct classifications. Moreover, almost all of them were “incorrectly” clustered by hierarchical classification, and positions of these populations in the PCA ordination plot are within clusters of different taxa. Such populations require further attention. For example, these results may indicate previously unrecognized hybridization.  


The results can be exported to the clipboard or file using the `exportRes()` function. In the example below, posterior probabilities of classification of an individual into each group are exported. 

```{r echo = TRUE, eval=FALSE}
classif_lda = classif.matrix(classifRes.lda, level = "indiv")
exportRes(object = classif_lda,
          file = "lda_classifMatrix.txt")
```



&nbsp;   
&nbsp;  

The **k-nearest neighbour** method classifies an individual according to the *a priori* classification of its k neighbours (by Euclidean distance) using a majority vote. As this method uses Euclidean distance, the characters are standardised to a zero mean and a unit variance. The cross-validation mode can be set as `"indiv"` or `"pop"`, in the same manner as above.

The optimal number of neighbours to consider is unknown, but it is empirically estimated from the data. The `knn.select()` searches for the optimal k for the given data set. The function can use two cross-validation methods (by individuals and populations) in a similar way as the classificatory discriminant analysis functions (the latter is used in the example below). The function compute the number of correctly classified individuals for k values from 1 to 30 and highlight the value with the highest success rate. Ties (i.e., when there are the same numbers of votes for two or more groups) are broken at random, and thus several iterations may yield different results. Therefore, the functions compute 10 iterations, and the average success rates for each k are used; the minimum and maximum success rates for each k are also displayed as error bars. Note that several k values may have nearly the same success rates; if this is the case, the similarity of iterations may also be considered. 


```{r echo = FALSE, eval = TRUE}
knn.select<-function(object, crossval="indiv"){
  k = as.numeric(1:30)
  ksel = matrix(c(423,423,423,423,423,423,423,423,423,423
                  ,415,406,415,407,403,417,409,403,413,403
                  ,442,437,438,438,435,434,434,436,436,440
                  ,447,445,438,440,441,443,441,438,440,436
                  ,447,453,448,448,448,448,449,448,450,449
                  ,454,455,445,440,449,449,446,447,456,441
                  ,449,452,450,448,447,454,448,448,453,447
                  ,448,442,443,458,450,453,454,454,451,445
                  ,449,450,452,450,450,452,449,449,451,450
                  ,456,447,452,450,446,447,449,451,450,457
                  ,454,453,453,451,453,453,455,454,452,457
                  ,459,455,461,454,451,455,452,455,453,458
                  ,454,450,454,455,453,453,451,448,451,454
                  ,452,447,454,453,452,450,454,454,447,448
                  ,451,453,453,454,452,452,455,450,452,451
                  ,451,451,456,453,454,455,455,452,451,454
                  ,452,455,452,452,451,452,452,451,451,450
                  ,450,449,448,445,451,447,447,448,448,444
                  ,453,452,453,449,452,451,452,449,451,450
                  ,448,452,451,447,451,447,447,451,452,451
                  ,448,447,448,448,448,447,453,449,448,445
                  ,450,449,451,449,451,449,449,449,450,451
                  ,447,448,448,449,448,448,449,449,451,449
                  ,444,446,445,443,444,446,443,444,444,446
                  ,449,451,449,446,450,448,449,448,450,448
                  ,449,449,448,446,448,449,449,449,451,448
                  ,447,449,446,445,444,448,449,446,447,447
                  ,447,444,445,446,445,447,448,446,445,447
                  ,449,448,447,447,446,448,447,448,448,450
                  ,445,448,448,450,448,446,447,450,447,449), byrow = T, ncol = 10)
  
  ksel = t(ksel)
  
  for (j in 1:10)
  {
    cat("Tested ", j*10, "% of Ks \n")
  }
  
  kselmean = apply(ksel, MARGIN = 2, FUN = mean)
  kselmax = apply(ksel, MARGIN = 2, FUN = max)
  kselmin = apply(ksel, MARGIN = 2, FUN = min)
  graphics::plot(kselmean,type="p",pch=16,xlab="K",ylab="correct classifications", ylim=c(min(kselmin),max(kselmax)))

  sapply(k[-1],function(x) graphics::arrows(x, kselmin[x], x, kselmax[x], code = 3, angle = 90, length = 0.07))

  cat("\nThe highest number of correct classifications is at k = 12)\n")
}
```



```{r echo = TRUE, eval=TRUE, out.width = '320px', dpi=300}
knn.select(centaurea, crossval = "pop")
```

The highest number of correct classifications is at k = 12, thus we set `k = 12` in the `classif.knn()` function (to classify individual according its 12 nearest neighbours).

```{r echo = TRUE, eval=TRUE}
classifRes.knn = classif.knn(centaurea, crossval = "pop", k = 12)

classif.matrix(classifRes.knn, level = "taxon")
```

The results can be exported with the `exportRes()` function.

```{r echo = TRUE, eval=FALSE}
popClassifMatrix = classif.matrix(classifRes.knn, level = "taxon")

exportRes(popClassifMatrix, file = "clipboard")
```



The another functions, `classifSample.lda()` and `classifSample.knn()` are designed to classify hybrid populations, type herbarium specimens, atypical samples, entirely new data, etc. Discriminant criterion is developed from the original (training) dataset and applied to the specific sample (set).  

&nbsp;  

Let's remove population PRIS and pretend that sample PRIS418 is a type herbarium specimen of *Centaurea pseudophrygia* and we want to show its similarity with other populations of the species (typically, we have only morphology for old herbarium collections while we have other data for recently studied populations – but to assess their taxonomic identity, we should compare them with types ). To classify PRIS418, run the following code:

```{r echo = TRUE, eval=TRUE}
trainingSet = deletePopulation(centaurea, populationName = "PRIS")
typeSpecimen = keepSample(centaurea, "PRIS418")

classifSample.lda(typeSpecimen, trainingSet)

```

The probability, that sample PRIS418 is *C. pseudophrygia* is over 90%. 





# Further reading

A brief account of the multivariate methods used in taxonomy is given in:  

**Marhold K. (2011)**. Multivariate morphometrics and its application to monography at specific and infraspecific levels. In: Stuessy TF, Lack HW, eds. *Monographic plant systematics: fundamental assessment of plant biodiversity*. Ruggell: A.R.G. Gantner Verlag K. G., 73–99.  

For a detailed description of used methods see:

**Legendre P. & Legendre L. (2012)**. *Numerical Ecology*, 3rd English edn. Elsevier Science BV, Amsterdam.



&nbsp;  

Selection of papers employing the methods of multivariate morphometrics:

**Lihová J, Kudoh H, Marhold K. (2010).** Morphometric studies of polyploid *Cardamine* species (Brassicaceae) from Japan: solving a long-standing taxonomic and nomenclatural controversy. *Australian Systematic Botany* 23, 94-111. doi: 10.1071/sb09038

**Melichárková A, Španiel S, Marhold K, Hurdu BI, Drescher A, Zozomová-Lihová J. (2019)**. Diversification and independent polyploid origins in the disjunct species *Alyssum repens* from the Southeastern Alps and the Carpathians. *American Journal of Botany* 106, 1499-1518. doi: 10.1002/ajb2.1370

**Skokanová K, Hodálová I, Mereďa P, Slovák M, Kučera, J. (2019)**. The *Cyanus tuberosus* group (Asteraceae) in the Balkans: biological entities require correct names. *Plant Systematics and Evolution* 305, 569–596. doi: 10.1007/s00606-019-01576-4

**Šlenker M, Zozomová-Lihová J, Mandáková T, Kudoh H, Zhao Y, Soejima A, et al. (2018)**. Morphology and genome size of the widespread weed *Cardamine occulta*: how it differs from cleistogamic *C. kokaiensis* and other closely related taxa in Europe and Asia. *Botanical Journal of the Linnean Society* 187, 456-482. doi: 10.1093/botlinnean/boy030

**Španiel S, Marhold K, Passalacqua NG, Zozomová-Lihová J. (2011)**. Intricate variation patterns in the diploid-polyploid complex of *Alyssum montanum-A. repens* (Brassicaceae) in the Apennine Peninsula: Evidence for long-term persistence and diversification. *American Journal of Botany* 98, 1887-1904. doi: 10.3732/ajb.1100147

**Šrámková G, Kolář F, Záveská E, Lučanová M, Španiel S, Kolník M, et al. (2019)**. Phylogeography and taxonomic reassessment of *Arabidopsis halleri* - a montane species from Central Europe. *Plant Systematics and Evolution* 305, 885-898. doi: 10.1007/s00606-019-01625-y




# References

**Friendly M, Fox J. (2020)**. candisc: Visualizing Generalized Canonical Discriminant and Canonical
  Correlation Analysis. R package version 0.8-3. https://CRAN.R-project.org/package=candisc

**Klecka WR. (1980)**. *Discriminant analysis (No. 19)*. Sage University Paper Series on Quantitative Applications in the Social Sciences 07-019.

**Koutecký P. (2007)**. Morphological and ploidy level variation of Centaurea phrygia agg.(Asteraceae) in the Czech Republic, Slovakia and Ukraine. *Folia Geobotanica*, 42, 77-102.

**Koutecký P. (2015)**. MorphoTools: a set of R functions for morphometric analysis. *Plant Systematics and Evolution*, 301, 1115-1121.

**Koutecký P, Štěpánek J, Baďurová T. (2012)**. Differentiation between diploid and tetraploid Centaurea phrygia: mating barriers, morphology and geographic distribution. *Preslia* 84, 1-32.

**Shlens, J. (2014)**. A tutorial on principal component analysis. *ArXiv* preprint arXiv:1404.1100

**Thorpe RS. (1976)**. Biometric analysis of geographic variation and racial affinities. *Biological Reviews of the Cambridge Philosophical Society* 51, 407–425.

**Venables WN, Ripley BD. (2002)**. *Modern Applied Statistics with S, Fourth edition*. New York: Springer. 





```{r echo = FALSE, eval=TRUE}
# rm unwanted files
unlink("centaurea_TCS.txt")

```


